{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LangChain æ ¸å¿ƒç»„ä»¶ LLMs and ChatModels\n",
    "\n",
    "## å¦‚ä½•è°ƒç”¨ä»¥åŠåŒºåˆ«\n",
    "\n",
    "## - OpenAI ä¸ ChatOpenAI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<think>\n",
      "\n",
      "</think>\n",
      "\n",
      "ä½ å¥½ï¼å¾ˆé«˜å…´è§åˆ°ä½ ï¼Œæœ‰ä»€ä¹ˆæˆ‘å¯ä»¥å¸®å¿™çš„å—ï¼Ÿæ— è®ºæ˜¯é—®é¢˜ã€å»ºè®®è¿˜æ˜¯é—²èŠï¼Œæˆ‘éƒ½åœ¨è¿™å„¿ç­‰ç€ä½ å‘¢ï¼ğŸ˜Š\n"
     ]
    }
   ],
   "source": [
    "from langchain_ollama import OllamaLLM\n",
    "\n",
    "# æŒ‡å®šæœ¬åœ°æ¨¡å‹åç§°æˆ–è·¯å¾„\n",
    "ollama_llm = OllamaLLM(\n",
    "    model=\"deepseek-r1:1.5b\",  # ä¾‹å¦‚DeepSeek-R1 1.5Bæ¨¡å‹\n",
    "    base_url=\"http://localhost:11434\",  # Ollamaé»˜è®¤åœ°å€\n",
    "    type=\"llm\",  # æŒ‡å®šæ¨¡å‹ç±»å‹ä¸ºLLM\n",
    ")\n",
    "print(ollama_llm.invoke(\"ä½ å¥½\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<think>\n",
      "\n",
      "</think>\n",
      "\n",
      "ä½ å¥½ï¼å¾ˆé«˜å…´è§åˆ°ä½ ï¼Œæœ‰ä»€ä¹ˆæˆ‘å¯ä»¥å¸®å¿™çš„å—ï¼Ÿæ— è®ºæ˜¯å­¦ä¹ ã€å·¥ä½œè¿˜æ˜¯ç”Ÿæ´»ä¸­çš„é—®é¢˜ï¼Œéƒ½å¯ä»¥å‘Šè¯‰æˆ‘å“¦ï¼ğŸ˜Š\n"
     ]
    }
   ],
   "source": [
    "from langchain_ollama import ChatOllama\n",
    "\n",
    "# æŒ‡å®šæœ¬åœ°æ¨¡å‹åç§°æˆ–è·¯å¾„\n",
    "ollama_llm = ChatOllama(\n",
    "    model=\"deepseek-r1:1.5b\",  # ä¾‹å¦‚DeepSeek-R1 1.5Bæ¨¡å‹\n",
    "    type=\"chat\",  # æŒ‡å®šæ¨¡å‹ç±»å‹ä¸ºLLM\n",
    "    base_url=\"http://localhost:11434\"  # Ollamaé»˜è®¤åœ°å€\n",
    ")\n",
    "out = ollama_llm.invoke(\"ä½ å¥½\")\n",
    "print(out.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<think>\n",
      "è§‚å¯Ÿç»™å®šçš„ç­‰å¼ï¼š\n",
      "\n",
      "1 + 2 = 4  \n",
      "2 + 4 = 16  \n",
      "3 + 6 = 36  \n",
      "\n",
      "é¦–å…ˆï¼Œå‘ç°æ¯ä¸ªç­‰å¼çš„å·¦è¾¹æ•°å­—ä¼¼ä¹æœ‰è§„å¾‹ã€‚ä¾‹å¦‚ï¼Œåœ¨ç¬¬ä¸€ä¸ªç­‰å¼ä¸­ï¼Œ1 å’Œ 2 çš„å’Œæ˜¯ 3ï¼›åœ¨ç¬¬äºŒä¸ªç­‰å¼ä¸­ï¼Œ2 å’Œ 4 çš„å’Œæ˜¯ 6ï¼›ç¬¬ä¸‰ä¸ªç­‰å¼ä¸­ï¼Œ3 å’Œ 6 çš„å’Œæ˜¯ 9ã€‚\n",
      "\n",
      "æ¥ä¸‹æ¥ï¼Œè®¡ç®—å³è¾¹çš„ç»“æœï¼š\n",
      "\n",
      "1 + 2 = 4  \n",
      "2 + 4 = 16  \n",
      "3 + 6 = 36  \n",
      "\n",
      "è§‚å¯Ÿå³è¾¹ç»“æœï¼š4, 16, 36ã€‚è¿™äº›æ•°å­—çœ‹èµ·æ¥åƒæ˜¯å¹³æ–¹æ•°ï¼š2Â²=4ï¼Œ4Â²=16ï¼Œ6Â²=36ã€‚\n",
      "\n",
      "æ¥ä¸‹æ¥ï¼Œç¡®å®šåŠ æ•°ä¹‹é—´çš„å…³ç³»ï¼š\n",
      "\n",
      "ç¬¬ä¸€ä¸ªç­‰å¼å·¦è¾¹æ˜¯ 1 å’Œ 2ï¼Œå³è¾¹çš„4å¯ä»¥è¡¨ç¤ºä¸º (1Ã—2)Â² = 4  \n",
      "ç¬¬äºŒä¸ªç­‰å¼å·¦è¾¹æ˜¯ 2 å’Œ 4ï¼Œå³è¾¹çš„16å¯ä»¥è¡¨ç¤ºä¸º (2Ã—4)Â² = 16  \n",
      "ç¬¬ä¸‰ä¸ªç­‰å¼å·¦è¾¹æ˜¯3å’Œ6ï¼Œå³è¾¹çš„36å¯ä»¥è¡¨ç¤ºä¸º (3Ã—6)Â² = 36  \n",
      "\n",
      "å› æ­¤ï¼Œå¯ä»¥çœ‹å‡ºè§„å¾‹ä¸ºï¼šå½“ç»™å®šä¸¤ä¸ªæ•°aå’Œbæ—¶ï¼Œå…¶ç›¸åŠ çš„ç»“æœç­‰äºå®ƒä»¬ä¹˜ç§¯çš„å¹³æ–¹ã€‚\n",
      "\n",
      "åº”ç”¨è¿™ä¸ªè§„å¾‹åˆ°ç¬¬å››ä¸ªç­‰å¼ï¼š\n",
      "\n",
      "4 + 8  \n",
      "è®¡ç®—ä¹˜ç§¯ï¼š4 Ã— 8 = 32  \n",
      "ç„¶åæ±‚å¹³æ–¹ï¼š32Â² = 1024  \n",
      "\n",
      "å› æ­¤ï¼Œ4 + 8 åº”è¯¥ç­‰äº 1024ã€‚\n",
      "</think>\n",
      "\n",
      "æˆ‘ä»¬éœ€è¦æ‰¾å‡ºä¸€ä¸ªè§„å¾‹ï¼Œä½¿å¾—æ¯ä¸ªç­‰å¼å·¦è¾¹çš„ä¸¤ä¸ªæ•°ç›¸åŠ çš„ç»“æœç­‰äºå³è¾¹çš„å¹³æ–¹ã€‚\n",
      "\n",
      "è§‚å¯Ÿç»™å‡ºçš„ä¾‹å­ï¼š\n",
      "\n",
      "\\[\n",
      "1 + 2 = 4  \n",
      "\\]\n",
      "\\[\n",
      "2 + 4 = 16  \n",
      "\\]\n",
      "\\[\n",
      "3 + 6 = 36  \n",
      "\\]\n",
      "\n",
      "æˆ‘ä»¬å‘ç°å³è¾¹çš„æ•°å­—æ˜¯å·¦è¾¹æ•°å­—ä¹˜ç§¯çš„å¹³æ–¹ï¼š\n",
      "\n",
      "- \\( (1 \\times 2) = 2 \\)ï¼Œ\\( 2^2 = 4 \\)\n",
      "- \\( (2 \\times 4) = 8 \\)ï¼Œ\\( 8^2 = 64 \\)ï¼ˆä½†ç»™å‡ºçš„ç»“æœå´æ˜¯16ï¼Œè¿™ä¸ç¬¦åˆï¼‰\n",
      "  \n",
      "å“¦ï¼Œè¿™é‡Œå¯èƒ½éœ€è¦é‡æ–°åˆ†æã€‚\n",
      "\n",
      "å†ä»”ç»†çœ‹çœ‹ï¼š\n",
      "\n",
      "\\[\n",
      "(1 + 2) \\times (1 + 2) = 3 \\times 3 = 9 \\neq 4  \n",
      "\\]\n",
      "\\[\n",
      "(2 + 4) \\times (2 + 4) = 6 \\times 6 = 36 \\neq 16  \n",
      "\\]\n",
      "\n",
      "ä¸å¯¹ï¼Œå†å°è¯•å¦ä¸€ç§æ€è·¯ï¼š\n",
      "\n",
      "å¯èƒ½å³è¾¹çš„ç»“æœæ˜¯ \\( (a + b)^2 \\)ï¼Œä½†å®é™…ä¸Šï¼š\n",
      "\n",
      "\\[\n",
      "1 + 2 = 4 \\quad \\Rightarrow \\quad 4 = 2^2  \n",
      "\\]\n",
      "\\[\n",
      "2 + 4 = 16 \\quad \\Rightarrow \\quad 16 = 4^2  \n",
      "\\]\n",
      "\\[\n",
      "3 + 6 = 36 \\quad \\Rightarrow \\quad 36 = 6^2  \n",
      "\\]\n",
      "\n",
      "å“¦ï¼ŒåŸæ¥è§„å¾‹æ˜¯ï¼šå½“ \\( a + b = n \\) æ—¶ï¼Œå³è¾¹ç»“æœä¸º \\( n^2 \\)ã€‚\n",
      "\n",
      "æ‰€ä»¥ï¼š\n",
      "\n",
      "\\[\n",
      "4 + 8 = ?  \n",
      "\\]\n",
      "è®¡ç®—å·¦è¾¹çš„å’Œï¼š\n",
      "\\[\n",
      "4 + 8 = 12  \n",
      "\\]\n",
      "é‚£ä¹ˆå³è¾¹çš„ç»“æœå°±æ˜¯ï¼š\n",
      "\\[\n",
      "12^2 = 144  \n",
      "\\]\n",
      "\n",
      "å› æ­¤ï¼Œ\n",
      "\n",
      "\\[\n",
      "\\boxed{144}\n",
      "\\]\n"
     ]
    }
   ],
   "source": [
    "from langchain_ollama import ChatOllama\n",
    "from langchain.schema.messages import AIMessage,HumanMessage\n",
    "# æŒ‡å®šæœ¬åœ°æ¨¡å‹åç§°æˆ–è·¯å¾„\n",
    "ollama_llm = ChatOllama(\n",
    "    model=\"deepseek-r1:1.5b\",  # ä¾‹å¦‚DeepSeek-R1 1.5Bæ¨¡å‹\n",
    "    type=\"chat\",  # æŒ‡å®šæ¨¡å‹ç±»å‹ä¸ºLLM\n",
    "    base_url=\"http://localhost:11434\"  # Ollamaé»˜è®¤åœ°å€\n",
    ")\n",
    "\n",
    "msg = [\n",
    "    HumanMessage(role=\"user\",content=\"æœ‰ 1 + 2 = 4\"),\n",
    "    HumanMessage(role=\"user\",content=\"æœ‰ 2 + 4 = 16\"),\n",
    "    HumanMessage(role=\"user\",content=\"æœ‰ 3 + 6 = 36\"),\n",
    "    HumanMessage(role=\"user\",content=\"4 + 8 = ?\"),\n",
    "]\n",
    "\n",
    "out = ollama_llm.invoke(msg)\n",
    "print(out.content)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## æµè¾“å‡º"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<think>\n",
      "é¦–å…ˆï¼Œæˆ‘çœ‹åˆ°é¢˜ç›®æ˜¯è®¡ç®—4åŠ 8ã€‚\n",
      "\n",
      "ç„¶åï¼Œæˆ‘æƒ³åˆ°ç›´æ¥ç”¨åŠ æ³•çš„æ–¹æ³•ï¼ŒæŠŠ4å’Œ8åˆå¹¶èµ·æ¥å¾—åˆ°12ã€‚\n",
      "\n",
      "æœ€åï¼Œæˆ‘ç¡®è®¤ä¸€ä¸‹ç»“æœæ˜¯å¦æ­£ç¡®ï¼Œç¡®ä¿æ²¡æœ‰é—æ¼æˆ–è€…é”™è¯¯ã€‚\n",
      "</think>\n",
      "\n",
      "è¦è®¡ç®— \\(4 + 8\\)ï¼Œæˆ‘ä»¬å¯ä»¥æŒ‰ç…§ä»¥ä¸‹æ­¥éª¤è¿›è¡Œï¼š\n",
      "\n",
      "**æ­¥éª¤ä¸€ï¼šè¯†åˆ«æ•°å­—**\n",
      "- å‡æ•°æ˜¯4\n",
      "- è¢«å‡æ•°æ˜¯8\n",
      "\n",
      "**æ­¥éª¤äºŒï¼šç›´æ¥ç›¸åŠ **\n",
      "\\[\n",
      "4 + 8 = 12\n",
      "\\]\n",
      "\n",
      "**æœ€ç»ˆç­”æ¡ˆï¼š**\n",
      "\\[\n",
      "\\boxed{12}\n",
      "\\]"
     ]
    }
   ],
   "source": [
    "from langchain_ollama import ChatOllama\n",
    "from langchain.schema.messages import AIMessage,HumanMessage\n",
    "# æŒ‡å®šæœ¬åœ°æ¨¡å‹åç§°æˆ–è·¯å¾„\n",
    "ollama_llm = ChatOllama(\n",
    "    model=\"deepseek-r1:1.5b\",  # ä¾‹å¦‚DeepSeek-R1 1.5Bæ¨¡å‹\n",
    "    type=\"chat\",  # æŒ‡å®šæ¨¡å‹ç±»å‹ä¸ºLLM\n",
    "    base_url=\"http://localhost:11434\"  # Ollamaé»˜è®¤åœ°å€\n",
    ")\n",
    "\n",
    "msg = [\n",
    "    HumanMessage(role=\"user\",content=\"æœ‰ 1 + 2 = 4\"),\n",
    "    HumanMessage(role=\"user\",content=\"æœ‰ 2 + 4 = 16\"),\n",
    "    HumanMessage(role=\"user\",content=\"æœ‰ 3 + 6 = 36\"),\n",
    "]\n",
    "\n",
    "# ä½¿ç”¨æµå¼è¾“å‡ºå›ç­”\n",
    "for out in ollama_llm.stream(\"è®¡ç®— 4 + 8 = ?\"):\n",
    "    print(out.content, end=\"\", flush=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<think>\n",
      "å—¯ï¼Œç”¨æˆ·è®©æˆ‘å†™ä¸€é¦–å…³äºæ˜¥å¤©çš„äº”è¨€ç»å¥ï¼Œè¦æ±‚è¡¨è¾¾æ˜¥å¤©çš„ç¾å¥½å’Œä¸ªäººçš„å®ä¼ŸæŠ±è´Ÿã€‚é¦–å…ˆï¼Œæˆ‘å¾—è€ƒè™‘äº”è¨€ç»å¥çš„ç»“æ„ï¼Œå››å¥ï¼Œæ¯å¥äº”ä¸ªå­—ï¼ŒæŠ¼éŸµã€‚æ˜¥å¤©æœ‰æ˜¥é›¨ã€èŠ±å¼€ã€é¸Ÿè¯­ç­‰æ„è±¡ã€‚\n",
      "\n",
      "ç¬¬ä¸€å¥ï¼Œè¦æç»˜æ˜¥å¤©çš„æ™¯è±¡ã€‚æ¯”å¦‚â€œæ˜¥æ³¥â€è±¡å¾é’è‰ç”Ÿé•¿ï¼Œâ€œè‰å¶â€ä»£è¡¨å«©ç»¿ã€‚è¿™ä¸¤è€…ç»“åˆèƒ½è¡¨ç°è‡ªç„¶çš„ç”Ÿæœºä¸å˜åŒ–ã€‚â€œæ˜¥æ³¥è‰å¶è½¬æ–°çº¢â€ï¼Œè¿™æ ·æ—¢ç‚¹æ˜äº†é¢œè‰²ï¼Œåˆçªå‡ºäº†æ˜¥å¤©çš„å˜åŒ–ã€‚\n",
      "\n",
      "ç¬¬äºŒå¥éœ€è¦è¡¨è¾¾ç¾å¥½çš„æƒ…ç»ªæˆ–ç§¯æçš„æ„Ÿè§‰ã€‚å¯ä»¥æ¯”ä½œæ˜¥é£å¸¦æ¥å¸Œæœ›å’Œå¹¸ç¦ï¼Œâ€œæ˜¥é£æ»¡é¢æ˜ é«˜å°â€ã€‚è¿™æ ·ä¸ä»…æç»˜æ™¯è±¡ï¼Œè¿˜ä¼ è¾¾äº†ç§¯æå‘ä¸Šçš„æƒ…æ„Ÿã€‚\n",
      "\n",
      "ç¬¬ä¸‰å¥åº”è¯¥å‡åä¸»é¢˜ï¼Œå¯èƒ½æ¶‰åŠè¿œå¤§çš„æŠ±è´Ÿã€‚æ¯”å¦‚â€œè¿œæœ›å±±åŸè§å®å›¾â€ï¼Œè¡¨ç°å‡ºå¯¹æœªæ¥çš„ä¿¡å¿ƒå’Œé›„å¿ƒå£®å¿—ã€‚\n",
      "\n",
      "æœ€åä¸€å¥è¦æ€»ç»“æ˜¥å¤©çš„ç¾å¥½ï¼Œæˆ–è€…å‘¼åº”å¼€å¤´ã€‚â€œæ˜¥å…‰æš–æ—¥æš–äº‘å®½â€ï¼Œè¿™æ ·ä¸ä»…æç»˜äº†å…·ä½“çš„æ™¯è±¡ï¼Œè¿˜ä¼ è¾¾å‡ºæ¸©æš–å’Œè°çš„æ°›å›´ã€‚\n",
      "\n",
      "æ•´ä½“ä¸Šï¼Œæˆ‘ç¡®ä¿æ¯å¥éƒ½ç´§æ‰£ä¸»é¢˜ï¼Œæ—¢æœ‰è‡ªç„¶æ™¯è‰²åˆå«è“„åœ°è¡¨è¾¾äº†ä¸ªäººçš„æŠ±è´Ÿã€‚åŒæ—¶æŠ¼éŸµå’Œå¯¹ä»—ä¹Ÿè¦æ³¨æ„ï¼Œè®©æ•´é¦–è¯—æµç•…è‡ªç„¶ã€‚\n",
      "</think>\n",
      "\n",
      "ã€Šæ˜¥å…‰æš–æ—¥æš–äº‘å®½ã€‹\n",
      "æ˜¥æ³¥è‰å¶è½¬æ–°çº¢ï¼Œ\n",
      "æ˜¥é£æ»¡é¢æ˜ é«˜å°ã€‚\n",
      "è¿œæœ›å±±åŸè§å®å›¾ï¼Œ\n",
      "æ˜¥å…‰æš–æ—¥æš–äº‘å®½ã€‚\n",
      "\n",
      "èµæï¼šè¿™é¦–ä½œå“æç»˜äº†æ˜¥å¤©çš„ç¾æ™¯å’Œä¸ªäººæŠ±è´Ÿã€‚è¯—ä¸­â€œæ˜¥æ³¥è‰å¶è½¬æ–°çº¢â€å±•ç°è‡ªç„¶ç”Ÿæœºï¼Œâ€œæ˜¥é£æ»¡é¢æ˜ é«˜å°â€åˆ™å¯“æƒ…äºæ™¯ï¼Œè¡¨è¾¾äº†å¯¹ç¾å¥½æ—¶å…‰çš„æœŸå¾…ä¸æ»¡è¶³ã€‚å°¾è”â€œè¿œæœ›å±±åŸè§å®å›¾â€æ›´æ˜¯ä»¥è¿œå¤§å¿—å‘æ”¶å°¾ï¼Œå±•ç°äº†ä½œè€…è¿œå¤§çš„æŠ±è´Ÿå’Œåšå®šçš„æƒ…æ€€ã€‚"
     ]
    }
   ],
   "source": [
    "from langchain_ollama import OllamaLLM\n",
    "\n",
    "# æŒ‡å®šæœ¬åœ°æ¨¡å‹åç§°æˆ–è·¯å¾„\n",
    "ollama_llm = OllamaLLM(\n",
    "    model=\"deepseek-r1:1.5b\",  # ä¾‹å¦‚DeepSeek-R1 1.5Bæ¨¡å‹\n",
    "    base_url=\"http://localhost:11434\",  # Ollamaé»˜è®¤åœ°å€\n",
    "    type=\"llm\",  # æŒ‡å®šæ¨¡å‹ç±»å‹ä¸ºLLM\n",
    ")\n",
    "# ä½¿ç”¨æµå¼è¾“å‡ºå›ç­”\n",
    "for out in ollama_llm.stream(\"å†™ä¸€é¦–å…³äºæ˜¥å¤©çš„è¯—ï¼Œ ä½¿ç”¨äº”è¨€ç»å¥ï¼Œ è¦è¡¨è¾¾æ˜¥å¤©çš„ç¾å¥½ï¼Œ è¡¨è¾¾å®ä¼Ÿçš„ä¸ªäººæŠ±è´Ÿ\"):\n",
    "    print(out, end=\"\", flush=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## æ€»ç»“\n",
    "LLM çš„ æµå¼è°ƒç”¨ \n",
    "```python\n",
    "for out in ollama_llm.stream(\"å†™ä¸€é¦–å…³äºæ˜¥å¤©çš„è¯—ï¼Œ ä½¿ç”¨äº”è¨€ç»å¥ï¼Œ è¦è¡¨è¾¾æ˜¥å¤©çš„ç¾å¥½ï¼Œ è¡¨è¾¾å®ä¼Ÿçš„ä¸ªäººæŠ±è´Ÿ\"):\n",
    "    print(out, end=\"\", flush=False)\n",
    "```\n",
    "Chat æµå¼è°ƒç”¨\n",
    "```python\n",
    "for out in ollama_llm.stream(\"è®¡ç®— 4 + 8 = ?\"):\n",
    "    print(out.content, end=\"\", flush=False)\n",
    "```"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "AI_Class",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
