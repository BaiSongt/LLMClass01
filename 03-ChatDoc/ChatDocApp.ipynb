{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 用自然语言和文档聊天"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/Caskroom/miniconda/base/envs/rag/lib/python3.13/site-packages/langchain_core/vectorstores/base.py:1077: UserWarning: Relevance scores must be between 0 and 1, got [(Document(metadata={'source': 'files/file.docx'}, page_content='第七条 争议解决\\n\\n合同履行中发生争议，双方应协商解决；协商不成可向乙方所在地人民法院提起诉讼。  \\n\\n第八条 其他条款\\n\\n1. 本合同一式两份，甲乙双方各执一份，自签字后生效。'), -199.5608430044063)]\n",
      "  self.vectorstore.similarity_search_with_relevance_scores(\n",
      "No relevant docs were retrieved using the relevance score threshold 0.5\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "AIMessage(content='这个合同有 10 条主要条款和附加 3 项补充协议。', additional_kwargs={}, response_metadata={'model': 'llama3.1:8b', 'created_at': '2025-03-25T03:28:48.621461Z', 'done': True, 'done_reason': 'stop', 'total_duration': 1995486917, 'load_duration': 35131209, 'prompt_eval_count': 80, 'prompt_eval_duration': 717038083, 'eval_count': 20, 'eval_duration': 1241929542, 'message': Message(role='assistant', content='', images=None, tool_calls=None)}, id='run-1c56f198-e7ab-4d5e-baaa-e57f11861a8b-0', usage_metadata={'input_tokens': 80, 'output_tokens': 20, 'total_tokens': 100})"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 导入必须的包\n",
    "from langchain.document_loaders import Docx2txtLoader\n",
    "from langchain.document_loaders import PyPDFLoader\n",
    "from langchain.document_loaders import UnstructuredExcelLoader\n",
    "from langchain.text_splitter import CharacterTextSplitter\n",
    "\n",
    "# from langchain.embeddings import OpenAIEmbeddings\n",
    "from langchain.embeddings import OllamaEmbeddings\n",
    "from langchain.vectorstores import Chroma\n",
    "\n",
    "# 引入Chat model\n",
    "from langchain_ollama.chat_models import ChatOllama\n",
    "from langchain.prompts import ChatPromptTemplate\n",
    "\n",
    "# 定义ChatDoc\n",
    "class ChatDoc():\n",
    "  def __init__(self):\n",
    "    self.doc = None\n",
    "    self.splitText = []\n",
    "    self.template = [\n",
    "      (\"system\", \"你是一个合同草拟的专家，你从不说自己是大模型或智能助手, \\\n",
    "                  你会根据下面提供的上下文内容来回答我的问题。\\n 上下文内容 \\n {context} \\n\"),\n",
    "      (\"human\", \"你好！\"),\n",
    "      (\"ai\", \"你好！\"),\n",
    "      (\"human\", \"{question}\")\n",
    "    ]\n",
    "    self.prompt = ChatPromptTemplate.from_messages(self.template)\n",
    "\n",
    "  def getFile(self):\n",
    "    doc = self.doc\n",
    "    loaders = {\n",
    "      \"docx\":Docx2txtLoader,\n",
    "      \"pdf\":PyPDFLoader,\n",
    "      \"xlsx\":UnstructuredExcelLoader\n",
    "    }\n",
    "    file_extension = doc.split(\".\")[-1]\n",
    "    loader_class = loaders.get(file_extension)\n",
    "    if loader_class:\n",
    "      try:\n",
    "        loader = loader_class(doc)\n",
    "        text = loader.load()\n",
    "        return text\n",
    "      except Exception as e:\n",
    "        print(f\"Error Loading {file_extension} files: {e}\")\n",
    "    else:\n",
    "      print(f\"Unsupported Loading {file_extension} files: {e}\")\n",
    "      return None\n",
    "\n",
    "  # 文档分割\n",
    "  def splitSentences(self):\n",
    "    full_text = self.getFile()\n",
    "    if full_text != None :\n",
    "      # 对文档进行切割\n",
    "      text_splitter = CharacterTextSplitter(chunk_size=100, chunk_overlap=20)\n",
    "      texts = text_splitter.split_documents(full_text)\n",
    "      self.splitText = texts\n",
    "\n",
    "  # 向量化与向量存储\n",
    "  def embeddingAndVectorDB(self):\n",
    "    # embeddings = OpenAIEmbeddings()\n",
    "\n",
    "    embeddings = OllamaEmbeddings(\n",
    "      base_url=\"http://localhost:11434\",\n",
    "      model=\"nomic-embed-text:latest\"\n",
    "    )\n",
    "    chroma_db = Chroma.from_documents(\n",
    "      documents=self.splitText,\n",
    "      embedding=embeddings\n",
    "    )\n",
    "    return chroma_db\n",
    "\n",
    "  # 提问并找到相关的文本块\n",
    "  def askAndFindFiles(self, question):\n",
    "    db = self.embeddingAndVectorDB()\n",
    "    # retriever = db.as_retriever(search_type='mmr')\n",
    "    retriever = db.as_retriever(search_type=\"similarity_score_threshold\",\n",
    "                                search_kwargs = {\"score_threshold\":.5, \"k\":1})\n",
    "    return retriever.get_relevant_documents(query=question)\n",
    "\n",
    "  # Chat with Document By 自然语言\n",
    "  def chatWithDoc(self, question):\n",
    "    _content = \"\"\n",
    "    context = self.askAndFindFiles(question)\n",
    "    for i in context:\n",
    "      _content += i.page_content\n",
    "\n",
    "    messages = self.prompt.format_messages(context=_content, question=question)\n",
    "    chat = ChatOllama(\n",
    "      model=\"llama3.1:8b\"\n",
    "    )\n",
    "    return chat.invoke(messages)\n",
    "\n",
    "\n",
    "chat_doc = ChatDoc()\n",
    "chat_doc.doc = \"files/file.docx\"\n",
    "chat_doc.splitSentences()\n",
    "chat_doc.chatWithDoc(\"合同一共多少条目\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "rag",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
