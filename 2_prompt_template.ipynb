{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prompt Template 提示词模板"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## prompt template  字符模板"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'你是一个AI模型专家'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 字符模板\n",
    "from langchain.prompts import PromptTemplate\n",
    "\n",
    "prompt = PromptTemplate.from_template(\"你是一个{area}专家\")\n",
    "prompt.format(area=\"AI模型\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 对话模板 ChatPromptTemplate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[SystemMessage(content='You are a helpful assistant.', additional_kwargs={}, response_metadata={}),\n",
       " AIMessage(content='I am an AI model.', additional_kwargs={}, response_metadata={}),\n",
       " HumanMessage(content='Hello my AI!', additional_kwargs={}, response_metadata={}),\n",
       " AIMessage(content='ai_response', additional_kwargs={}, response_metadata={})]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain.prompts import ChatPromptTemplate\n",
    "\n",
    "chat_template = ChatPromptTemplate.from_messages([\n",
    "   (\"system\", \"You are a helpful assistant.\"),\n",
    "   (\"ai\", \"I am an AI model.\"),\n",
    "   (\"human\", \"{user_input}\"),\n",
    "   (\"assistant\", \"ai_response\"),\n",
    "  #  (\"xxxx\", \"JJJJJJ\")\n",
    "  # Unexpected message type: xxxx.\n",
    "  # Use one of 'human', 'user', 'ai', 'assistant', or 'system'.\n",
    "])\n",
    "chat_template.format_messages(user_input=\"Hello my AI!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[SystemMessage(content='You are a helpful assistant.', additional_kwargs={'name': 'system'}, response_metadata={}),\n",
       " HumanMessage(content='You are a helpful assistant.', additional_kwargs={'name': 'human'}, response_metadata={}),\n",
       " AIMessage(content='I am an AI model.', additional_kwargs={}, response_metadata={})]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain.schema import HumanMessage, AIMessage, SystemMessage\n",
    "\n",
    "sm = SystemMessage(content='You are a helpful assistant.', additional_kwargs={'name': 'system'})\n",
    "h_m = HumanMessage(content='You are a helpful assistant.', additional_kwargs={'name': 'human'})\n",
    "ai_m = AIMessage(content='I am an AI model.')\n",
    "[sm, h_m, ai_m]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ChatMassagePromptTemplate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ChatMessage(content='愿DDDD荣光永存！', additional_kwargs={}, response_metadata={}, role='father')"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain.prompts import SystemMessagePromptTemplate\n",
    "from langchain.prompts import HumanMessagePromptTemplate\n",
    "from langchain.prompts import AIMessagePromptTemplate\n",
    "from langchain.prompts import ChatMessagePromptTemplate\n",
    "\n",
    "pt = \"愿{obj}荣光永存！\"\n",
    "\n",
    "sys_template = SystemMessagePromptTemplate.from_template(template=pt)\n",
    "sys_template.format(obj=\"AAA\")\n",
    "\n",
    "hum_template = HumanMessagePromptTemplate.from_template(template=pt)\n",
    "hum_template.format(obj=\"BBB\")\n",
    "\n",
    "ai_template = AIMessagePromptTemplate.from_template(template=pt)\n",
    "ai_template.format(obj=\"CCCC\")\n",
    "\n",
    "fat_template = ChatMessagePromptTemplate.from_template(role='father', template=pt)\n",
    "fat_template.format(obj=\"DDDD\")\n",
    "\n",
    "# [sys_template, hum_template, ai_template, fat_template]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 自定义模板 StringPromptTemplate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<think>\n",
      "嗯，我现在要解析这个函数。首先，函数名是add，参数都是int类型，返回值也是int。看起来这是一个简单的加法函数。\n",
      "\n",
      "参数列表部分，我需要列出x和y的类型和位置。x在第一个位置，y在第二个位置，都是int型。\n",
      "\n",
      "返回值类型很简单，就是int，直接写出来就可以了。\n",
      "\n",
      "函数体的话，按照def的格式来写，参数用逗号分隔，后面加->，然后是return语句，把x+y写进去。\n",
      "\n",
      "功能解释部分，我需要简要说明这个函数的作用，比如可以用来计算两个整数的和。这样用户就能明白它的作用了。\n",
      "\n",
      "示例代码的话，我可以举个例子，比如add(3,4)应该返回7，或者add(-1,2)返回1。这样大家都能看到它怎么用。\n",
      "\n",
      "现在把这些信息整理成格式化的输出吧。\n",
      "</think>\n",
      "\n",
      "函数解析如下：\n",
      "\n",
      "- 1. 函数名：add\n",
      "- 2. 参数列表：\n",
      "  - x: int\n",
      "  - y: int\n",
      "- 3. 返回值类型：int\n",
      "- 4. 函数体：\n",
      "  def add(x: int, y: int) -> int:\n",
      "    return x + y\n",
      "- 5. 功能解释：\n",
      "  这个函数定义了一个名为add的函数，它接受两个参数x和y，这两个参数都是整数类型。函数的功能是将这两个整数相加，并返回结果。\n",
      "- 6. 示例代码：\n",
      "  add(3,4) → 7\n",
      "  add(-1,2) → 1\n"
     ]
    }
   ],
   "source": [
    "# AI函数解析器\n",
    "from langchain.prompts import StringPromptTemplate\n",
    "\n",
    "# 定义一个简单的函数\n",
    "def add(x: int, y: int) -> int:\n",
    "    return x + y\n",
    "\n",
    "# 创建一个自定义提示词模板\n",
    "PROMPT=\"\"\"\\\n",
    "你是一个函数解析器, 可以解析函数的参数和返回值。\n",
    "根据给定的函数内容:{function_body},解析出一下内容：\n",
    "参数列表, 返回值类型, 函数功能解释, 示例代码。\n",
    "按照以下格式输出:\n",
    "\n",
    "函数解析如下：\n",
    "- 1. 函数名：{function_name}\n",
    "- 2. 参数列表：\n",
    "- 3. 返回值类型：\n",
    "- 4. 函数体：\n",
    "     {function_body}\n",
    "- 5. 功能解释：\n",
    "- 6. 示例代码：\n",
    "\"\"\"\n",
    "\n",
    "import inspect\n",
    "\n",
    "def get_function_source(func):\n",
    "    # 获取函数信息\n",
    "    return inspect.getsource(func)\n",
    "\n",
    "\n",
    "# 创建一个自定义的提示词模板类\n",
    "class CustomPromptTemplate(StringPromptTemplate):\n",
    "    def format(self, **kwargs):\n",
    "        # 获得源代码信息\n",
    "        func = kwargs.pop(\"function\")\n",
    "        func_info = get_function_source(func)\n",
    "        return PROMPT.format(\n",
    "            function_name=func.__name__,\n",
    "            function_body=func_info,\n",
    "        )\n",
    "\n",
    "\n",
    "# 创建一个StringPromptTemplate实例\n",
    "custom_pt = CustomPromptTemplate(input_variables=[\"function\"])\n",
    "cpt_str = custom_pt.format(function=add)\n",
    "\n",
    "# 将生成的模板输入给AI\n",
    "from langchain_ollama import ChatOllama\n",
    "\n",
    "# 指定本地模型名称或路径\n",
    "ollama_llm = ChatOllama(\n",
    "    model=\"deepseek-r1:1.5b\",  # 例如DeepSeek-R1 1.5B模型\n",
    "    base_url=\"http://localhost:11434\",  # Ollama默认地址\n",
    "    temperature=0,\n",
    ")\n",
    "print(ollama_llm.predict(cpt_str))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## f-string 和 jinja2 模板提示词格式化"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The answer is 42\n"
     ]
    }
   ],
   "source": [
    "from langchain.prompts import PromptTemplate\n",
    "# 使用f-string模板提示词格式化\n",
    "f_string_template = \"\"\"The answer is {answer}\"\"\"\n",
    "f_string_prompt = PromptTemplate.from_template(f_string_template)\n",
    "print(f_string_prompt.format(answer=42))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The answer is 42\n"
     ]
    }
   ],
   "source": [
    "from langchain.prompts import PromptTemplate\n",
    "# 适应 jinia2 模板引擎\n",
    "jinja2_template = \"The answer is {{ answer }}\"\n",
    "jinja2_prompt = PromptTemplate.from_template(jinja2_template, template_format=\"jinja2\")\n",
    "print(jinja2_prompt.format(answer=42))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "______\n",
    "## 组合模板"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- final proprompt  生成最终的提示词\n",
    "- pipeline prompt template 用于组合多个prompts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.prompts.pipeline import PipelinePromptTemplate\n",
    "from langchain.prompts.prompt import PromptTemplate"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 三层提示词设计\n",
    "- 外层prompt: 指定输入和输出格式，以及模板引擎\n",
    "- 中间层prompt：指定模型的参数\n",
    "- 最终层prompt: 组合多个prompts\n",
    "  \n",
    " 1. 定义外层prompt template   \n",
    " 2. 定义中间层prompt template \n",
    " 3. 组合两个提示词"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input_variables=['behavior', 'character', 'prohibition'] input_types={} partial_variables={} template='\\n{character},\\n{behavior},\\n{prohibition}\\n'\n"
     ]
    }
   ],
   "source": [
    "# final prompt 由一系列变量构成\n",
    "FINAL_PROMPT = \"\"\"\n",
    "{character},\n",
    "{behavior},\n",
    "{prohibition}\n",
    "\"\"\"\n",
    "\n",
    "full_prompt_template = PromptTemplate.from_template(FINAL_PROMPT)\n",
    "print(full_prompt_template)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 第一层提示词设计 「character」"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "chara_prompt = \"\"\"你是{persion}, 你是公司总裁\"\"\"\n",
    "chara_prompt_template = PromptTemplate.from_template(chara_prompt)\n",
    "# print(chara_prompt_template)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 第二层提示词设计 「behavior」"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "behavior_prompt = \"\"\"你遵从以下行为：{behavior_list}\"\"\"\n",
    "behavior_prompt_template = PromptTemplate.from_template(behavior_prompt)\n",
    "# print(behavior_prompt_template)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 第三层提示词设计 「prohibition」"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "prohibition_prompt = \"\"\"禁止使用以下词汇：{prohibition_list}\"\"\"\n",
    "prohibition_prompt_template = PromptTemplate.from_template(prohibition_prompt)\n",
    "# print(behavior_prompt_template)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 组合提示词\n",
    "```\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "text=\"\\n你是星际大亨, 你是公司总裁,\\n你遵从以下行为：不准打人,\\n禁止使用以下词汇：['打人', '骂人']\\n\"\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "A PipelinePrompt consists of two main parts:\n",
    "- final_prompt: This is the final prompt that is returned\n",
    "- pipeline_prompts: This is a list of tuples, consisting of\n",
    "    a string (name) and a Prompt Template. Each PromptTemplate\n",
    "    will be formatted and then passed to future prompt templates\n",
    "    as a variable with the same name as name\n",
    "\"\"\"\n",
    "\n",
    "pipeline_prompt = (\n",
    "   (\"character\", chara_prompt_template),\n",
    "   (\"behavior\", behavior_prompt_template),\n",
    "   (\"prohibition\", prohibition_prompt_template))\n",
    "# print(pipeline_prompt)\n",
    "\n",
    "# pipline_prompt = PipelinePromptTemplate(final_prompt=FINAL_PROMPT, pipeline_prompts=pipeline_prompt)\n",
    "\n",
    "# 组合参数\n",
    "my_input = {\n",
    "    \"persion\": \"星际大亨\",\n",
    "    \"behavior_list\": \"不准打人\",\n",
    "    \"prohibition_list\": [\"打人\",\"骂人\"]\n",
    "}\n",
    "\n",
    "\n",
    "for key, pt in pipeline_prompt:\n",
    "    my_input[key] = pt.invoke(my_input).to_string()\n",
    "my_output = full_prompt_template.invoke(my_input)\n",
    "print(my_output)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "AI_Class",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
