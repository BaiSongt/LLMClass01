{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 文档转换器 Transform\n",
    "#### 原理\n",
    "- 1 将文档分成小的，有意义的块（句子）\n",
    "- 2 将小块组合成一个更大的块，直到到达一定的大小\n",
    "- 3 一旦达到一定的大小，接着开始创建与下一个块重叠的部分\n",
    "\n",
    "### 示例\n",
    "- 第一个文档分割\n",
    "- 按照字符切割\n",
    "- 代码文档分割\n",
    "- 按照token来分"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# 第一个文档分割"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 递归字符分割器 `RecursiveCharacterTextSplitter`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "page_content='大型语言模型（LLM' metadata={'start_index': 0}\n",
      "page_content='，Large Language Model）是一种基于深度学习技术的自然语言处理模型' metadata={'start_index': 10}\n",
      "page_content='。它通过训练海量的文本数据' metadata={'start_index': 52}\n",
      "page_content='，能够理解和生成自然语言文本' metadata={'start_index': 65}\n",
      "page_content='。LLM的核心是使用神经网络' metadata={'start_index': 79}\n",
      "page_content='，特别是变压器（Transformer）架构' metadata={'start_index': 93}\n",
      "page_content='，这种架构能够有效地捕捉文本中的上下文关系' metadata={'start_index': 115}\n",
      "page_content='，从而生成连贯且有意义的文本' metadata={'start_index': 136}\n",
      "page_content='。\n",
      "LLM的应用范围非常广泛' metadata={'start_index': 150}\n",
      "page_content='，包括但不限于机器翻译、文本摘要、对话系统、内容生成和情感分析等' metadata={'start_index': 164}\n",
      "page_content='。通过预训练和微调' metadata={'start_index': 196}\n",
      "page_content='，LLM可以在不同的任务中表现出色。例如' metadata={'start_index': 205}\n",
      "page_content='，GPT-3是目前最先进的LLM之一' metadata={'start_index': 225}\n",
      "page_content='，它拥有1750亿个参数' metadata={'start_index': 243}\n",
      "page_content='，能够生成高质量的文本' metadata={'start_index': 255}\n",
      "page_content='，并且在许多自然语言处理任务中达到了接近人类的表现' metadata={'start_index': 266}\n",
      "page_content='。\n",
      "尽管LLM在许多方面表现出色' metadata={'start_index': 291}\n",
      "page_content='，但它们也存在一些挑战和局限性。例如' metadata={'start_index': 307}\n",
      "page_content='，LLM需要大量的计算资源和数据进行训练' metadata={'start_index': 325}\n",
      "page_content='，且在生成内容时可能会产生偏见或不准确的信息' metadata={'start_index': 345}\n",
      "page_content='。因此' metadata={'start_index': 367}\n",
      "page_content='，研究人员和工程师们正在不断改进这些模型' metadata={'start_index': 370}\n",
      "page_content='，以提高其性能和可靠性。' metadata={'start_index': 390}\n"
     ]
    }
   ],
   "source": [
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "\n",
    "# 加载要切割的文档\n",
    "with open(\"loaded_files/splite.txt\") as sf :\n",
    "  LLM_introduction = sf.read()\n",
    "\n",
    "# 使用递归字符分割器\n",
    "spliter = RecursiveCharacterTextSplitter(\n",
    "  separators=['，','。'], # 分隔字符，按照该字符分割 默认为 \\n\\n\n",
    "  chunk_size=20, # 单个块大小， 一般按照长度函数计算\n",
    "  chunk_overlap=5, # 重叠块大小， 一般按照长度函数计算\n",
    "  length_function=len, # 长度计算函数，也可以用tokenize函数\n",
    "  add_start_index=True, # 是否添加开始索引\n",
    ")\n",
    "\n",
    "text = spliter.create_documents([LLM_introduction])\n",
    "for i in text :\n",
    "  print(i,end=\"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 按照字符进行分割 `CharacterTextSplitter`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Created a chunk of size 54, which is longer than the specified 20\n",
      "Created a chunk of size 27, which is longer than the specified 20\n",
      "Created a chunk of size 21, which is longer than the specified 20\n",
      "Created a chunk of size 27, which is longer than the specified 20\n",
      "Created a chunk of size 40, which is longer than the specified 20\n",
      "Created a chunk of size 40, which is longer than the specified 20\n",
      "Created a chunk of size 24, which is longer than the specified 20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "page_content='大型语言模型（LLM' metadata={'start_index': 0}\n",
      "page_content='Large Language Model）是一种基于深度学习技术的自然语言处理模型。它通过训练海量的文本数据' metadata={'start_index': 11}\n",
      "page_content='能够理解和生成自然语言文本。LLM的核心是使用神经网络' metadata={'start_index': 66}\n",
      "page_content='特别是变压器（Transformer）架构' metadata={'start_index': 94}\n",
      "page_content='这种架构能够有效地捕捉文本中的上下文关系' metadata={'start_index': 116}\n",
      "page_content='从而生成连贯且有意义的文本。\n",
      "LLM的应用范围非常广泛' metadata={'start_index': 137}\n",
      "page_content='包括但不限于机器翻译、文本摘要、对话系统、内容生成和情感分析等。通过预训练和微调' metadata={'start_index': 165}\n",
      "page_content='LLM可以在不同的任务中表现出色。例如' metadata={'start_index': 206}\n",
      "page_content='GPT-3是目前最先进的LLM之一' metadata={'start_index': 226}\n",
      "page_content='它拥有1750亿个参数' metadata={'start_index': 244}\n",
      "page_content='能够生成高质量的文本' metadata={'start_index': 256}\n",
      "page_content='并且在许多自然语言处理任务中达到了接近人类的表现。\n",
      "尽管LLM在许多方面表现出色' metadata={'start_index': 267}\n",
      "page_content='但它们也存在一些挑战和局限性。例如' metadata={'start_index': 308}\n",
      "page_content='LLM需要大量的计算资源和数据进行训练' metadata={'start_index': 326}\n",
      "page_content='且在生成内容时可能会产生偏见或不准确的信息。因此' metadata={'start_index': 346}\n",
      "page_content='研究人员和工程师们正在不断改进这些模型' metadata={'start_index': 371}\n",
      "page_content='以提高其性能和可靠性。' metadata={'start_index': 391}\n"
     ]
    }
   ],
   "source": [
    "from langchain.text_splitter import CharacterTextSplitter\n",
    "\n",
    "# 使用递归字符分割器\n",
    "spliter = CharacterTextSplitter(\n",
    "  separator=\"，\", # 分隔字符，按照该字符分割 默认为 \\n\\n\n",
    "  chunk_size=20, # 单个块大小， 一般按照长度函数计算\n",
    "  chunk_overlap=5, # 重叠块大小， 一般按照长度函数计算\n",
    "  length_function=len, # 长度计算函数，也可以用tokenize函数\n",
    "  add_start_index=True, # 是否添加开始索引\n",
    "  is_separator_regex=False, # 是否为正则表达式\n",
    ")\n",
    "\n",
    "text = spliter.create_documents([LLM_introduction])\n",
    "for i in text :\n",
    "  print(i,end=\"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 代码文档的切割 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Document(metadata={}, page_content='\"'), Document(metadata={}, page_content='def hello_world():\\n  print(\"Hello World!\")'), Document(metadata={}, page_content='# 调用函数\\nhello_world()')]\n"
     ]
    }
   ],
   "source": [
    "from langchain.text_splitter import (\n",
    "  RecursiveCharacterTextSplitter,\n",
    "  Language\n",
    ")\n",
    "\n",
    "# 支持解析的编程语言\n",
    "# [e.value for e in Language]\n",
    "\n",
    "py_code = \"\"\"\"\n",
    "def hello_world():\n",
    "  print(\"Hello World!\")\n",
    "\n",
    "# 调用函数\n",
    "hello_world()\n",
    "\"\"\"\n",
    "\n",
    "py_splitter = RecursiveCharacterTextSplitter.from_language(\n",
    "  language=Language.PYTHON,\n",
    "  chunk_size=50,\n",
    "  chunk_overlap=10,\n",
    ")\n",
    "\n",
    "python_docs = py_splitter.create_documents([py_code])\n",
    "print(python_docs)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 按 Token 分割"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Document(metadata={}, page_content='大型语言模型（LLM，Large Language Model）是一种基于深度学习技术的自然语言处理模型。它通过训练海量的文本数据，能够理解和生成自然语言文本。LLM的核心是使用神经网络，特别是变压器（Transformer）架构，这种架构能够有效地捕捉文本中的上下文关系，从而生成连贯且有意义的文本。\\nLLM的应用范围非常广泛，包括但不限于机器翻译、文本摘要、对话系统、内容生成和情感分析等。通过预训练和微调，LLM可以在不同的任务中表现出色。例如，GPT-3是目前最先进的LLM之一，它拥有1750亿个参数，能够生成高质量的文本，并且在许多自然语言处理任务中达到了接近人类的表现。\\n尽管LLM在许多方面表现出色，但它们也存在一些挑战和局限性。例如，LLM需要大量的计算资源和数据进行训练，且在生成内容时可能会产生偏见或不准确的信息。因此，研究人员和工程师们正在不断改进这些模型，以提高其性能和可靠性。')]\n"
     ]
    }
   ],
   "source": [
    "from langchain.text_splitter import CharacterTextSplitter\n",
    "# from tiktoken import Encoding\n",
    "\n",
    "# 加载要切割的文档\n",
    "# with open(\"loaded_files/splite.txt\") as sf :\n",
    "#   LLM_introduction = sf.read()\n",
    "\n",
    "# 创建编码器（需指定编码类型和词汇表路径）\n",
    "# encoder = Encoding(\"bpe\", \"path/to/vocab.json\")\n",
    "\n",
    "# 初始化分词器并传入编码器\n",
    "text_splitter = CharacterTextSplitter.from_tiktoken_encoder(\n",
    "    chunk_size=200,\n",
    "    chunk_overlap=10,\n",
    "    # encoder=encoder  # 关键参数\n",
    ")\n",
    "\n",
    "print(text_splitter.create_documents([LLM_introduction]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 文档的总结，精炼，翻译\n",
    "______"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! pip3 install doctran"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_ollama import OllamaLLM\n",
    "\n",
    "# 指定本地模型名称或路径\n",
    "ollama_llm = OllamaLLM(\n",
    "    model=\"deepseek-r1:1.5b\",  # 例如DeepSeek-R1 1.5B模型\n",
    "    base_url=\"http://localhost:11434\",  # Ollama默认地址\n",
    ")\n",
    "\n",
    "# load document\n",
    "with open(\"loaded_files/letter.txt\") as f :\n",
    "  content = f.read()\n",
    "\n",
    "from doctran import Doctran\n",
    "doctran = Doctran(openai_model=ollama_llm)\n",
    "\n",
    "documents = doctran.parse(content=content)\n",
    "\n",
    "## 总结\n",
    "summary = documents.summarize(token_limit=100).execute()\n",
    "print(summary.transformed_content)\n",
    "\n",
    "\n",
    "## 翻译\n",
    "\n",
    "trans = documents.translate(\n",
    "  language='zh-cn'\n",
    ")\n",
    "\n",
    "print(trans.execute().transformed_content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 精炼文档"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "refined = documents.refine(\n",
    "  topics=['missing']\n",
    ").execute()\n",
    "print(refined.transformed_content)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "AI_Class",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
