{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6c392b13",
   "metadata": {},
   "source": [
    "# LCEL 接口\n",
    "- 输入格式\n",
    "- 输出格式\n",
    "- 8 中不同的接口方式\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f0d000f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_ollama.chat_models import ChatOllama\n",
    "\n",
    "model = ChatOllama(model=\"qwen2.5:7b\")\n",
    "prompt = ChatPromptTemplate.from_template(\"给我讲一个关于{Topic}的故事\")\n",
    "\n",
    "chain = prompt | model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "eed311a3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/d6/8jzk9xqn419djvdnx23ft3y40000gn/T/ipykernel_17275/3338923589.py:2: PydanticDeprecatedSince20: The `schema` method is deprecated; use `model_json_schema` instead. Deprecated in Pydantic V2.0 to be removed in V3.0. See Pydantic V2 Migration Guide at https://errors.pydantic.dev/2.10/migration/\n",
      "  chain.input_schema.schema()\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'properties': {'Topic': {'title': 'Topic', 'type': 'string'}},\n",
       " 'required': ['Topic'],\n",
       " 'title': 'PromptInput',\n",
       " 'type': 'object'}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### input Schema 概要\n",
    "chain.input_schema.schema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9e402270",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/d6/8jzk9xqn419djvdnx23ft3y40000gn/T/ipykernel_17339/1594619117.py:1: PydanticDeprecatedSince20: The `schema` method is deprecated; use `model_json_schema` instead. Deprecated in Pydantic V2.0 to be removed in V3.0. See Pydantic V2 Migration Guide at https://errors.pydantic.dev/2.10/migration/\n",
      "  prompt.input_schema.schema()\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'properties': {'Topic': {'title': 'Topic', 'type': 'string'}},\n",
       " 'required': ['Topic'],\n",
       " 'title': 'PromptInput',\n",
       " 'type': 'object'}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prompt.input_schema.schema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a86bd0c2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'$defs': {'AIMessage': {'additionalProperties': True,\n",
       "   'description': 'Message from an AI.\\n\\nAIMessage is returned from a chat model as a response to a prompt.\\n\\nThis message represents the output of the model and consists of both\\nthe raw output as returned by the model together standardized fields\\n(e.g., tool calls, usage metadata) added by the LangChain framework.',\n",
       "   'properties': {'content': {'anyOf': [{'type': 'string'},\n",
       "      {'items': {'anyOf': [{'type': 'string'}, {'type': 'object'}]},\n",
       "       'type': 'array'}],\n",
       "     'title': 'Content'},\n",
       "    'additional_kwargs': {'title': 'Additional Kwargs', 'type': 'object'},\n",
       "    'response_metadata': {'title': 'Response Metadata', 'type': 'object'},\n",
       "    'type': {'const': 'ai',\n",
       "     'default': 'ai',\n",
       "     'title': 'Type',\n",
       "     'type': 'string'},\n",
       "    'name': {'anyOf': [{'type': 'string'}, {'type': 'null'}],\n",
       "     'default': None,\n",
       "     'title': 'Name'},\n",
       "    'id': {'anyOf': [{'type': 'string'}, {'type': 'null'}],\n",
       "     'default': None,\n",
       "     'title': 'Id'},\n",
       "    'example': {'default': False, 'title': 'Example', 'type': 'boolean'},\n",
       "    'tool_calls': {'default': [],\n",
       "     'items': {'$ref': '#/$defs/ToolCall'},\n",
       "     'title': 'Tool Calls',\n",
       "     'type': 'array'},\n",
       "    'invalid_tool_calls': {'default': [],\n",
       "     'items': {'$ref': '#/$defs/InvalidToolCall'},\n",
       "     'title': 'Invalid Tool Calls',\n",
       "     'type': 'array'},\n",
       "    'usage_metadata': {'anyOf': [{'$ref': '#/$defs/UsageMetadata'},\n",
       "      {'type': 'null'}],\n",
       "     'default': None}},\n",
       "   'required': ['content'],\n",
       "   'title': 'AIMessage',\n",
       "   'type': 'object'},\n",
       "  'AIMessageChunk': {'additionalProperties': True,\n",
       "   'description': 'Message chunk from an AI.',\n",
       "   'properties': {'content': {'anyOf': [{'type': 'string'},\n",
       "      {'items': {'anyOf': [{'type': 'string'}, {'type': 'object'}]},\n",
       "       'type': 'array'}],\n",
       "     'title': 'Content'},\n",
       "    'additional_kwargs': {'title': 'Additional Kwargs', 'type': 'object'},\n",
       "    'response_metadata': {'title': 'Response Metadata', 'type': 'object'},\n",
       "    'type': {'const': 'AIMessageChunk',\n",
       "     'default': 'AIMessageChunk',\n",
       "     'title': 'Type',\n",
       "     'type': 'string'},\n",
       "    'name': {'anyOf': [{'type': 'string'}, {'type': 'null'}],\n",
       "     'default': None,\n",
       "     'title': 'Name'},\n",
       "    'id': {'anyOf': [{'type': 'string'}, {'type': 'null'}],\n",
       "     'default': None,\n",
       "     'title': 'Id'},\n",
       "    'example': {'default': False, 'title': 'Example', 'type': 'boolean'},\n",
       "    'tool_calls': {'default': [],\n",
       "     'items': {'$ref': '#/$defs/ToolCall'},\n",
       "     'title': 'Tool Calls',\n",
       "     'type': 'array'},\n",
       "    'invalid_tool_calls': {'default': [],\n",
       "     'items': {'$ref': '#/$defs/InvalidToolCall'},\n",
       "     'title': 'Invalid Tool Calls',\n",
       "     'type': 'array'},\n",
       "    'usage_metadata': {'anyOf': [{'$ref': '#/$defs/UsageMetadata'},\n",
       "      {'type': 'null'}],\n",
       "     'default': None},\n",
       "    'tool_call_chunks': {'default': [],\n",
       "     'items': {'$ref': '#/$defs/ToolCallChunk'},\n",
       "     'title': 'Tool Call Chunks',\n",
       "     'type': 'array'}},\n",
       "   'required': ['content'],\n",
       "   'title': 'AIMessageChunk',\n",
       "   'type': 'object'},\n",
       "  'ChatMessage': {'additionalProperties': True,\n",
       "   'description': 'Message that can be assigned an arbitrary speaker (i.e. role).',\n",
       "   'properties': {'content': {'anyOf': [{'type': 'string'},\n",
       "      {'items': {'anyOf': [{'type': 'string'}, {'type': 'object'}]},\n",
       "       'type': 'array'}],\n",
       "     'title': 'Content'},\n",
       "    'additional_kwargs': {'title': 'Additional Kwargs', 'type': 'object'},\n",
       "    'response_metadata': {'title': 'Response Metadata', 'type': 'object'},\n",
       "    'type': {'const': 'chat',\n",
       "     'default': 'chat',\n",
       "     'title': 'Type',\n",
       "     'type': 'string'},\n",
       "    'name': {'anyOf': [{'type': 'string'}, {'type': 'null'}],\n",
       "     'default': None,\n",
       "     'title': 'Name'},\n",
       "    'id': {'anyOf': [{'type': 'string'}, {'type': 'null'}],\n",
       "     'default': None,\n",
       "     'title': 'Id'},\n",
       "    'role': {'title': 'Role', 'type': 'string'}},\n",
       "   'required': ['content', 'role'],\n",
       "   'title': 'ChatMessage',\n",
       "   'type': 'object'},\n",
       "  'ChatMessageChunk': {'additionalProperties': True,\n",
       "   'description': 'Chat Message chunk.',\n",
       "   'properties': {'content': {'anyOf': [{'type': 'string'},\n",
       "      {'items': {'anyOf': [{'type': 'string'}, {'type': 'object'}]},\n",
       "       'type': 'array'}],\n",
       "     'title': 'Content'},\n",
       "    'additional_kwargs': {'title': 'Additional Kwargs', 'type': 'object'},\n",
       "    'response_metadata': {'title': 'Response Metadata', 'type': 'object'},\n",
       "    'type': {'const': 'ChatMessageChunk',\n",
       "     'default': 'ChatMessageChunk',\n",
       "     'title': 'Type',\n",
       "     'type': 'string'},\n",
       "    'name': {'anyOf': [{'type': 'string'}, {'type': 'null'}],\n",
       "     'default': None,\n",
       "     'title': 'Name'},\n",
       "    'id': {'anyOf': [{'type': 'string'}, {'type': 'null'}],\n",
       "     'default': None,\n",
       "     'title': 'Id'},\n",
       "    'role': {'title': 'Role', 'type': 'string'}},\n",
       "   'required': ['content', 'role'],\n",
       "   'title': 'ChatMessageChunk',\n",
       "   'type': 'object'},\n",
       "  'ChatPromptValueConcrete': {'description': 'Chat prompt value which explicitly lists out the message types it accepts.\\nFor use in external schemas.',\n",
       "   'properties': {'messages': {'items': {'oneOf': [{'$ref': '#/$defs/AIMessage'},\n",
       "       {'$ref': '#/$defs/HumanMessage'},\n",
       "       {'$ref': '#/$defs/ChatMessage'},\n",
       "       {'$ref': '#/$defs/SystemMessage'},\n",
       "       {'$ref': '#/$defs/FunctionMessage'},\n",
       "       {'$ref': '#/$defs/ToolMessage'},\n",
       "       {'$ref': '#/$defs/AIMessageChunk'},\n",
       "       {'$ref': '#/$defs/HumanMessageChunk'},\n",
       "       {'$ref': '#/$defs/ChatMessageChunk'},\n",
       "       {'$ref': '#/$defs/SystemMessageChunk'},\n",
       "       {'$ref': '#/$defs/FunctionMessageChunk'},\n",
       "       {'$ref': '#/$defs/ToolMessageChunk'}]},\n",
       "     'title': 'Messages',\n",
       "     'type': 'array'},\n",
       "    'type': {'const': 'ChatPromptValueConcrete',\n",
       "     'default': 'ChatPromptValueConcrete',\n",
       "     'title': 'Type',\n",
       "     'type': 'string'}},\n",
       "   'required': ['messages'],\n",
       "   'title': 'ChatPromptValueConcrete',\n",
       "   'type': 'object'},\n",
       "  'FunctionMessage': {'additionalProperties': True,\n",
       "   'description': 'Message for passing the result of executing a tool back to a model.\\n\\nFunctionMessage are an older version of the ToolMessage schema, and\\ndo not contain the tool_call_id field.\\n\\nThe tool_call_id field is used to associate the tool call request with the\\ntool call response. This is useful in situations where a chat model is able\\nto request multiple tool calls in parallel.',\n",
       "   'properties': {'content': {'anyOf': [{'type': 'string'},\n",
       "      {'items': {'anyOf': [{'type': 'string'}, {'type': 'object'}]},\n",
       "       'type': 'array'}],\n",
       "     'title': 'Content'},\n",
       "    'additional_kwargs': {'title': 'Additional Kwargs', 'type': 'object'},\n",
       "    'response_metadata': {'title': 'Response Metadata', 'type': 'object'},\n",
       "    'type': {'const': 'function',\n",
       "     'default': 'function',\n",
       "     'title': 'Type',\n",
       "     'type': 'string'},\n",
       "    'name': {'title': 'Name', 'type': 'string'},\n",
       "    'id': {'anyOf': [{'type': 'string'}, {'type': 'null'}],\n",
       "     'default': None,\n",
       "     'title': 'Id'}},\n",
       "   'required': ['content', 'name'],\n",
       "   'title': 'FunctionMessage',\n",
       "   'type': 'object'},\n",
       "  'FunctionMessageChunk': {'additionalProperties': True,\n",
       "   'description': 'Function Message chunk.',\n",
       "   'properties': {'content': {'anyOf': [{'type': 'string'},\n",
       "      {'items': {'anyOf': [{'type': 'string'}, {'type': 'object'}]},\n",
       "       'type': 'array'}],\n",
       "     'title': 'Content'},\n",
       "    'additional_kwargs': {'title': 'Additional Kwargs', 'type': 'object'},\n",
       "    'response_metadata': {'title': 'Response Metadata', 'type': 'object'},\n",
       "    'type': {'const': 'FunctionMessageChunk',\n",
       "     'default': 'FunctionMessageChunk',\n",
       "     'title': 'Type',\n",
       "     'type': 'string'},\n",
       "    'name': {'title': 'Name', 'type': 'string'},\n",
       "    'id': {'anyOf': [{'type': 'string'}, {'type': 'null'}],\n",
       "     'default': None,\n",
       "     'title': 'Id'}},\n",
       "   'required': ['content', 'name'],\n",
       "   'title': 'FunctionMessageChunk',\n",
       "   'type': 'object'},\n",
       "  'HumanMessage': {'additionalProperties': True,\n",
       "   'description': 'Message from a human.\\n\\nHumanMessages are messages that are passed in from a human to the model.\\n\\nExample:\\n\\n    .. code-block:: python\\n\\n        from langchain_core.messages import HumanMessage, SystemMessage\\n\\n        messages = [\\n            SystemMessage(\\n                content=\"You are a helpful assistant! Your name is Bob.\"\\n            ),\\n            HumanMessage(\\n                content=\"What is your name?\"\\n            )\\n        ]\\n\\n        # Instantiate a chat model and invoke it with the messages\\n        model = ...\\n        print(model.invoke(messages))',\n",
       "   'properties': {'content': {'anyOf': [{'type': 'string'},\n",
       "      {'items': {'anyOf': [{'type': 'string'}, {'type': 'object'}]},\n",
       "       'type': 'array'}],\n",
       "     'title': 'Content'},\n",
       "    'additional_kwargs': {'title': 'Additional Kwargs', 'type': 'object'},\n",
       "    'response_metadata': {'title': 'Response Metadata', 'type': 'object'},\n",
       "    'type': {'const': 'human',\n",
       "     'default': 'human',\n",
       "     'title': 'Type',\n",
       "     'type': 'string'},\n",
       "    'name': {'anyOf': [{'type': 'string'}, {'type': 'null'}],\n",
       "     'default': None,\n",
       "     'title': 'Name'},\n",
       "    'id': {'anyOf': [{'type': 'string'}, {'type': 'null'}],\n",
       "     'default': None,\n",
       "     'title': 'Id'},\n",
       "    'example': {'default': False, 'title': 'Example', 'type': 'boolean'}},\n",
       "   'required': ['content'],\n",
       "   'title': 'HumanMessage',\n",
       "   'type': 'object'},\n",
       "  'HumanMessageChunk': {'additionalProperties': True,\n",
       "   'description': 'Human Message chunk.',\n",
       "   'properties': {'content': {'anyOf': [{'type': 'string'},\n",
       "      {'items': {'anyOf': [{'type': 'string'}, {'type': 'object'}]},\n",
       "       'type': 'array'}],\n",
       "     'title': 'Content'},\n",
       "    'additional_kwargs': {'title': 'Additional Kwargs', 'type': 'object'},\n",
       "    'response_metadata': {'title': 'Response Metadata', 'type': 'object'},\n",
       "    'type': {'const': 'HumanMessageChunk',\n",
       "     'default': 'HumanMessageChunk',\n",
       "     'title': 'Type',\n",
       "     'type': 'string'},\n",
       "    'name': {'anyOf': [{'type': 'string'}, {'type': 'null'}],\n",
       "     'default': None,\n",
       "     'title': 'Name'},\n",
       "    'id': {'anyOf': [{'type': 'string'}, {'type': 'null'}],\n",
       "     'default': None,\n",
       "     'title': 'Id'},\n",
       "    'example': {'default': False, 'title': 'Example', 'type': 'boolean'}},\n",
       "   'required': ['content'],\n",
       "   'title': 'HumanMessageChunk',\n",
       "   'type': 'object'},\n",
       "  'InputTokenDetails': {'description': 'Breakdown of input token counts.\\n\\nDoes *not* need to sum to full input token count. Does *not* need to have all keys.\\n\\nExample:\\n\\n    .. code-block:: python\\n\\n        {\\n            \"audio\": 10,\\n            \"cache_creation\": 200,\\n            \"cache_read\": 100,\\n        }\\n\\n.. versionadded:: 0.3.9',\n",
       "   'properties': {'audio': {'title': 'Audio', 'type': 'integer'},\n",
       "    'cache_creation': {'title': 'Cache Creation', 'type': 'integer'},\n",
       "    'cache_read': {'title': 'Cache Read', 'type': 'integer'}},\n",
       "   'title': 'InputTokenDetails',\n",
       "   'type': 'object'},\n",
       "  'InvalidToolCall': {'description': 'Allowance for errors made by LLM.\\n\\nHere we add an `error` key to surface errors made during generation\\n(e.g., invalid JSON arguments.)',\n",
       "   'properties': {'name': {'anyOf': [{'type': 'string'}, {'type': 'null'}],\n",
       "     'title': 'Name'},\n",
       "    'args': {'anyOf': [{'type': 'string'}, {'type': 'null'}], 'title': 'Args'},\n",
       "    'id': {'anyOf': [{'type': 'string'}, {'type': 'null'}], 'title': 'Id'},\n",
       "    'error': {'anyOf': [{'type': 'string'}, {'type': 'null'}],\n",
       "     'title': 'Error'},\n",
       "    'type': {'const': 'invalid_tool_call', 'title': 'Type', 'type': 'string'}},\n",
       "   'required': ['name', 'args', 'id', 'error'],\n",
       "   'title': 'InvalidToolCall',\n",
       "   'type': 'object'},\n",
       "  'OutputTokenDetails': {'description': 'Breakdown of output token counts.\\n\\nDoes *not* need to sum to full output token count. Does *not* need to have all keys.\\n\\nExample:\\n\\n    .. code-block:: python\\n\\n        {\\n            \"audio\": 10,\\n            \"reasoning\": 200,\\n        }\\n\\n.. versionadded:: 0.3.9',\n",
       "   'properties': {'audio': {'title': 'Audio', 'type': 'integer'},\n",
       "    'reasoning': {'title': 'Reasoning', 'type': 'integer'}},\n",
       "   'title': 'OutputTokenDetails',\n",
       "   'type': 'object'},\n",
       "  'StringPromptValue': {'description': 'String prompt value.',\n",
       "   'properties': {'text': {'title': 'Text', 'type': 'string'},\n",
       "    'type': {'const': 'StringPromptValue',\n",
       "     'default': 'StringPromptValue',\n",
       "     'title': 'Type',\n",
       "     'type': 'string'}},\n",
       "   'required': ['text'],\n",
       "   'title': 'StringPromptValue',\n",
       "   'type': 'object'},\n",
       "  'SystemMessage': {'additionalProperties': True,\n",
       "   'description': 'Message for priming AI behavior.\\n\\nThe system message is usually passed in as the first of a sequence\\nof input messages.\\n\\nExample:\\n\\n    .. code-block:: python\\n\\n        from langchain_core.messages import HumanMessage, SystemMessage\\n\\n        messages = [\\n            SystemMessage(\\n                content=\"You are a helpful assistant! Your name is Bob.\"\\n            ),\\n            HumanMessage(\\n                content=\"What is your name?\"\\n            )\\n        ]\\n\\n        # Define a chat model and invoke it with the messages\\n        print(model.invoke(messages))',\n",
       "   'properties': {'content': {'anyOf': [{'type': 'string'},\n",
       "      {'items': {'anyOf': [{'type': 'string'}, {'type': 'object'}]},\n",
       "       'type': 'array'}],\n",
       "     'title': 'Content'},\n",
       "    'additional_kwargs': {'title': 'Additional Kwargs', 'type': 'object'},\n",
       "    'response_metadata': {'title': 'Response Metadata', 'type': 'object'},\n",
       "    'type': {'const': 'system',\n",
       "     'default': 'system',\n",
       "     'title': 'Type',\n",
       "     'type': 'string'},\n",
       "    'name': {'anyOf': [{'type': 'string'}, {'type': 'null'}],\n",
       "     'default': None,\n",
       "     'title': 'Name'},\n",
       "    'id': {'anyOf': [{'type': 'string'}, {'type': 'null'}],\n",
       "     'default': None,\n",
       "     'title': 'Id'}},\n",
       "   'required': ['content'],\n",
       "   'title': 'SystemMessage',\n",
       "   'type': 'object'},\n",
       "  'SystemMessageChunk': {'additionalProperties': True,\n",
       "   'description': 'System Message chunk.',\n",
       "   'properties': {'content': {'anyOf': [{'type': 'string'},\n",
       "      {'items': {'anyOf': [{'type': 'string'}, {'type': 'object'}]},\n",
       "       'type': 'array'}],\n",
       "     'title': 'Content'},\n",
       "    'additional_kwargs': {'title': 'Additional Kwargs', 'type': 'object'},\n",
       "    'response_metadata': {'title': 'Response Metadata', 'type': 'object'},\n",
       "    'type': {'const': 'SystemMessageChunk',\n",
       "     'default': 'SystemMessageChunk',\n",
       "     'title': 'Type',\n",
       "     'type': 'string'},\n",
       "    'name': {'anyOf': [{'type': 'string'}, {'type': 'null'}],\n",
       "     'default': None,\n",
       "     'title': 'Name'},\n",
       "    'id': {'anyOf': [{'type': 'string'}, {'type': 'null'}],\n",
       "     'default': None,\n",
       "     'title': 'Id'}},\n",
       "   'required': ['content'],\n",
       "   'title': 'SystemMessageChunk',\n",
       "   'type': 'object'},\n",
       "  'ToolCall': {'description': 'Represents a request to call a tool.\\n\\nExample:\\n\\n    .. code-block:: python\\n\\n        {\\n            \"name\": \"foo\",\\n            \"args\": {\"a\": 1},\\n            \"id\": \"123\"\\n        }\\n\\n    This represents a request to call the tool named \"foo\" with arguments {\"a\": 1}\\n    and an identifier of \"123\".',\n",
       "   'properties': {'name': {'title': 'Name', 'type': 'string'},\n",
       "    'args': {'title': 'Args', 'type': 'object'},\n",
       "    'id': {'anyOf': [{'type': 'string'}, {'type': 'null'}], 'title': 'Id'},\n",
       "    'type': {'const': 'tool_call', 'title': 'Type', 'type': 'string'}},\n",
       "   'required': ['name', 'args', 'id'],\n",
       "   'title': 'ToolCall',\n",
       "   'type': 'object'},\n",
       "  'ToolCallChunk': {'description': 'A chunk of a tool call (e.g., as part of a stream).\\n\\nWhen merging ToolCallChunks (e.g., via AIMessageChunk.__add__),\\nall string attributes are concatenated. Chunks are only merged if their\\nvalues of `index` are equal and not None.\\n\\nExample:\\n\\n.. code-block:: python\\n\\n    left_chunks = [ToolCallChunk(name=\"foo\", args=\\'{\"a\":\\', index=0)]\\n    right_chunks = [ToolCallChunk(name=None, args=\\'1}\\', index=0)]\\n\\n    (\\n        AIMessageChunk(content=\"\", tool_call_chunks=left_chunks)\\n        + AIMessageChunk(content=\"\", tool_call_chunks=right_chunks)\\n    ).tool_call_chunks == [ToolCallChunk(name=\\'foo\\', args=\\'{\"a\":1}\\', index=0)]',\n",
       "   'properties': {'name': {'anyOf': [{'type': 'string'}, {'type': 'null'}],\n",
       "     'title': 'Name'},\n",
       "    'args': {'anyOf': [{'type': 'string'}, {'type': 'null'}], 'title': 'Args'},\n",
       "    'id': {'anyOf': [{'type': 'string'}, {'type': 'null'}], 'title': 'Id'},\n",
       "    'index': {'anyOf': [{'type': 'integer'}, {'type': 'null'}],\n",
       "     'title': 'Index'},\n",
       "    'type': {'const': 'tool_call_chunk', 'title': 'Type', 'type': 'string'}},\n",
       "   'required': ['name', 'args', 'id', 'index'],\n",
       "   'title': 'ToolCallChunk',\n",
       "   'type': 'object'},\n",
       "  'ToolMessage': {'additionalProperties': True,\n",
       "   'description': 'Message for passing the result of executing a tool back to a model.\\n\\nToolMessages contain the result of a tool invocation. Typically, the result\\nis encoded inside the `content` field.\\n\\nExample: A ToolMessage representing a result of 42 from a tool call with id\\n\\n    .. code-block:: python\\n\\n        from langchain_core.messages import ToolMessage\\n\\n        ToolMessage(content=\\'42\\', tool_call_id=\\'call_Jja7J89XsjrOLA5r!MEOW!SL\\')\\n\\n\\nExample: A ToolMessage where only part of the tool output is sent to the model\\n    and the full output is passed in to artifact.\\n\\n    .. versionadded:: 0.2.17\\n\\n    .. code-block:: python\\n\\n        from langchain_core.messages import ToolMessage\\n\\n        tool_output = {\\n            \"stdout\": \"From the graph we can see that the correlation between x and y is ...\",\\n            \"stderr\": None,\\n            \"artifacts\": {\"type\": \"image\", \"base64_data\": \"/9j/4gIcSU...\"},\\n        }\\n\\n        ToolMessage(\\n            content=tool_output[\"stdout\"],\\n            artifact=tool_output,\\n            tool_call_id=\\'call_Jja7J89XsjrOLA5r!MEOW!SL\\',\\n        )\\n\\nThe tool_call_id field is used to associate the tool call request with the\\ntool call response. This is useful in situations where a chat model is able\\nto request multiple tool calls in parallel.',\n",
       "   'properties': {'content': {'anyOf': [{'type': 'string'},\n",
       "      {'items': {'anyOf': [{'type': 'string'}, {'type': 'object'}]},\n",
       "       'type': 'array'}],\n",
       "     'title': 'Content'},\n",
       "    'additional_kwargs': {'title': 'Additional Kwargs', 'type': 'object'},\n",
       "    'response_metadata': {'title': 'Response Metadata', 'type': 'object'},\n",
       "    'type': {'const': 'tool',\n",
       "     'default': 'tool',\n",
       "     'title': 'Type',\n",
       "     'type': 'string'},\n",
       "    'name': {'anyOf': [{'type': 'string'}, {'type': 'null'}],\n",
       "     'default': None,\n",
       "     'title': 'Name'},\n",
       "    'id': {'anyOf': [{'type': 'string'}, {'type': 'null'}],\n",
       "     'default': None,\n",
       "     'title': 'Id'},\n",
       "    'tool_call_id': {'title': 'Tool Call Id', 'type': 'string'},\n",
       "    'artifact': {'default': None, 'title': 'Artifact'},\n",
       "    'status': {'default': 'success',\n",
       "     'enum': ['success', 'error'],\n",
       "     'title': 'Status',\n",
       "     'type': 'string'}},\n",
       "   'required': ['content', 'tool_call_id'],\n",
       "   'title': 'ToolMessage',\n",
       "   'type': 'object'},\n",
       "  'ToolMessageChunk': {'additionalProperties': True,\n",
       "   'description': 'Tool Message chunk.',\n",
       "   'properties': {'content': {'anyOf': [{'type': 'string'},\n",
       "      {'items': {'anyOf': [{'type': 'string'}, {'type': 'object'}]},\n",
       "       'type': 'array'}],\n",
       "     'title': 'Content'},\n",
       "    'additional_kwargs': {'title': 'Additional Kwargs', 'type': 'object'},\n",
       "    'response_metadata': {'title': 'Response Metadata', 'type': 'object'},\n",
       "    'type': {'const': 'ToolMessageChunk',\n",
       "     'default': 'ToolMessageChunk',\n",
       "     'title': 'Type',\n",
       "     'type': 'string'},\n",
       "    'name': {'anyOf': [{'type': 'string'}, {'type': 'null'}],\n",
       "     'default': None,\n",
       "     'title': 'Name'},\n",
       "    'id': {'anyOf': [{'type': 'string'}, {'type': 'null'}],\n",
       "     'default': None,\n",
       "     'title': 'Id'},\n",
       "    'tool_call_id': {'title': 'Tool Call Id', 'type': 'string'},\n",
       "    'artifact': {'default': None, 'title': 'Artifact'},\n",
       "    'status': {'default': 'success',\n",
       "     'enum': ['success', 'error'],\n",
       "     'title': 'Status',\n",
       "     'type': 'string'}},\n",
       "   'required': ['content', 'tool_call_id'],\n",
       "   'title': 'ToolMessageChunk',\n",
       "   'type': 'object'},\n",
       "  'UsageMetadata': {'description': 'Usage metadata for a message, such as token counts.\\n\\nThis is a standard representation of token usage that is consistent across models.\\n\\nExample:\\n\\n    .. code-block:: python\\n\\n        {\\n            \"input_tokens\": 350,\\n            \"output_tokens\": 240,\\n            \"total_tokens\": 590,\\n            \"input_token_details\": {\\n                \"audio\": 10,\\n                \"cache_creation\": 200,\\n                \"cache_read\": 100,\\n            },\\n            \"output_token_details\": {\\n                \"audio\": 10,\\n                \"reasoning\": 200,\\n            }\\n        }\\n\\n.. versionchanged:: 0.3.9\\n\\n    Added ``input_token_details`` and ``output_token_details``.',\n",
       "   'properties': {'input_tokens': {'title': 'Input Tokens', 'type': 'integer'},\n",
       "    'output_tokens': {'title': 'Output Tokens', 'type': 'integer'},\n",
       "    'total_tokens': {'title': 'Total Tokens', 'type': 'integer'},\n",
       "    'input_token_details': {'$ref': '#/$defs/InputTokenDetails'},\n",
       "    'output_token_details': {'$ref': '#/$defs/OutputTokenDetails'}},\n",
       "   'required': ['input_tokens', 'output_tokens', 'total_tokens'],\n",
       "   'title': 'UsageMetadata',\n",
       "   'type': 'object'}},\n",
       " 'anyOf': [{'type': 'string'},\n",
       "  {'$ref': '#/$defs/StringPromptValue'},\n",
       "  {'$ref': '#/$defs/ChatPromptValueConcrete'},\n",
       "  {'items': {'oneOf': [{'$ref': '#/$defs/AIMessage'},\n",
       "     {'$ref': '#/$defs/HumanMessage'},\n",
       "     {'$ref': '#/$defs/ChatMessage'},\n",
       "     {'$ref': '#/$defs/SystemMessage'},\n",
       "     {'$ref': '#/$defs/FunctionMessage'},\n",
       "     {'$ref': '#/$defs/ToolMessage'},\n",
       "     {'$ref': '#/$defs/AIMessageChunk'},\n",
       "     {'$ref': '#/$defs/HumanMessageChunk'},\n",
       "     {'$ref': '#/$defs/ChatMessageChunk'},\n",
       "     {'$ref': '#/$defs/SystemMessageChunk'},\n",
       "     {'$ref': '#/$defs/FunctionMessageChunk'},\n",
       "     {'$ref': '#/$defs/ToolMessageChunk'}]},\n",
       "   'type': 'array'}],\n",
       " 'title': 'ChatOllamaInput'}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.input_schema.schema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1389d434",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'$defs': {'AIMessage': {'additionalProperties': True,\n",
       "   'description': 'Message from an AI.\\n\\nAIMessage is returned from a chat model as a response to a prompt.\\n\\nThis message represents the output of the model and consists of both\\nthe raw output as returned by the model together standardized fields\\n(e.g., tool calls, usage metadata) added by the LangChain framework.',\n",
       "   'properties': {'content': {'anyOf': [{'type': 'string'},\n",
       "      {'items': {'anyOf': [{'type': 'string'}, {'type': 'object'}]},\n",
       "       'type': 'array'}],\n",
       "     'title': 'Content'},\n",
       "    'additional_kwargs': {'title': 'Additional Kwargs', 'type': 'object'},\n",
       "    'response_metadata': {'title': 'Response Metadata', 'type': 'object'},\n",
       "    'type': {'const': 'ai',\n",
       "     'default': 'ai',\n",
       "     'title': 'Type',\n",
       "     'type': 'string'},\n",
       "    'name': {'anyOf': [{'type': 'string'}, {'type': 'null'}],\n",
       "     'default': None,\n",
       "     'title': 'Name'},\n",
       "    'id': {'anyOf': [{'type': 'string'}, {'type': 'null'}],\n",
       "     'default': None,\n",
       "     'title': 'Id'},\n",
       "    'example': {'default': False, 'title': 'Example', 'type': 'boolean'},\n",
       "    'tool_calls': {'default': [],\n",
       "     'items': {'$ref': '#/$defs/ToolCall'},\n",
       "     'title': 'Tool Calls',\n",
       "     'type': 'array'},\n",
       "    'invalid_tool_calls': {'default': [],\n",
       "     'items': {'$ref': '#/$defs/InvalidToolCall'},\n",
       "     'title': 'Invalid Tool Calls',\n",
       "     'type': 'array'},\n",
       "    'usage_metadata': {'anyOf': [{'$ref': '#/$defs/UsageMetadata'},\n",
       "      {'type': 'null'}],\n",
       "     'default': None}},\n",
       "   'required': ['content'],\n",
       "   'title': 'AIMessage',\n",
       "   'type': 'object'},\n",
       "  'AIMessageChunk': {'additionalProperties': True,\n",
       "   'description': 'Message chunk from an AI.',\n",
       "   'properties': {'content': {'anyOf': [{'type': 'string'},\n",
       "      {'items': {'anyOf': [{'type': 'string'}, {'type': 'object'}]},\n",
       "       'type': 'array'}],\n",
       "     'title': 'Content'},\n",
       "    'additional_kwargs': {'title': 'Additional Kwargs', 'type': 'object'},\n",
       "    'response_metadata': {'title': 'Response Metadata', 'type': 'object'},\n",
       "    'type': {'const': 'AIMessageChunk',\n",
       "     'default': 'AIMessageChunk',\n",
       "     'title': 'Type',\n",
       "     'type': 'string'},\n",
       "    'name': {'anyOf': [{'type': 'string'}, {'type': 'null'}],\n",
       "     'default': None,\n",
       "     'title': 'Name'},\n",
       "    'id': {'anyOf': [{'type': 'string'}, {'type': 'null'}],\n",
       "     'default': None,\n",
       "     'title': 'Id'},\n",
       "    'example': {'default': False, 'title': 'Example', 'type': 'boolean'},\n",
       "    'tool_calls': {'default': [],\n",
       "     'items': {'$ref': '#/$defs/ToolCall'},\n",
       "     'title': 'Tool Calls',\n",
       "     'type': 'array'},\n",
       "    'invalid_tool_calls': {'default': [],\n",
       "     'items': {'$ref': '#/$defs/InvalidToolCall'},\n",
       "     'title': 'Invalid Tool Calls',\n",
       "     'type': 'array'},\n",
       "    'usage_metadata': {'anyOf': [{'$ref': '#/$defs/UsageMetadata'},\n",
       "      {'type': 'null'}],\n",
       "     'default': None},\n",
       "    'tool_call_chunks': {'default': [],\n",
       "     'items': {'$ref': '#/$defs/ToolCallChunk'},\n",
       "     'title': 'Tool Call Chunks',\n",
       "     'type': 'array'}},\n",
       "   'required': ['content'],\n",
       "   'title': 'AIMessageChunk',\n",
       "   'type': 'object'},\n",
       "  'ChatMessage': {'additionalProperties': True,\n",
       "   'description': 'Message that can be assigned an arbitrary speaker (i.e. role).',\n",
       "   'properties': {'content': {'anyOf': [{'type': 'string'},\n",
       "      {'items': {'anyOf': [{'type': 'string'}, {'type': 'object'}]},\n",
       "       'type': 'array'}],\n",
       "     'title': 'Content'},\n",
       "    'additional_kwargs': {'title': 'Additional Kwargs', 'type': 'object'},\n",
       "    'response_metadata': {'title': 'Response Metadata', 'type': 'object'},\n",
       "    'type': {'const': 'chat',\n",
       "     'default': 'chat',\n",
       "     'title': 'Type',\n",
       "     'type': 'string'},\n",
       "    'name': {'anyOf': [{'type': 'string'}, {'type': 'null'}],\n",
       "     'default': None,\n",
       "     'title': 'Name'},\n",
       "    'id': {'anyOf': [{'type': 'string'}, {'type': 'null'}],\n",
       "     'default': None,\n",
       "     'title': 'Id'},\n",
       "    'role': {'title': 'Role', 'type': 'string'}},\n",
       "   'required': ['content', 'role'],\n",
       "   'title': 'ChatMessage',\n",
       "   'type': 'object'},\n",
       "  'ChatMessageChunk': {'additionalProperties': True,\n",
       "   'description': 'Chat Message chunk.',\n",
       "   'properties': {'content': {'anyOf': [{'type': 'string'},\n",
       "      {'items': {'anyOf': [{'type': 'string'}, {'type': 'object'}]},\n",
       "       'type': 'array'}],\n",
       "     'title': 'Content'},\n",
       "    'additional_kwargs': {'title': 'Additional Kwargs', 'type': 'object'},\n",
       "    'response_metadata': {'title': 'Response Metadata', 'type': 'object'},\n",
       "    'type': {'const': 'ChatMessageChunk',\n",
       "     'default': 'ChatMessageChunk',\n",
       "     'title': 'Type',\n",
       "     'type': 'string'},\n",
       "    'name': {'anyOf': [{'type': 'string'}, {'type': 'null'}],\n",
       "     'default': None,\n",
       "     'title': 'Name'},\n",
       "    'id': {'anyOf': [{'type': 'string'}, {'type': 'null'}],\n",
       "     'default': None,\n",
       "     'title': 'Id'},\n",
       "    'role': {'title': 'Role', 'type': 'string'}},\n",
       "   'required': ['content', 'role'],\n",
       "   'title': 'ChatMessageChunk',\n",
       "   'type': 'object'},\n",
       "  'FunctionMessage': {'additionalProperties': True,\n",
       "   'description': 'Message for passing the result of executing a tool back to a model.\\n\\nFunctionMessage are an older version of the ToolMessage schema, and\\ndo not contain the tool_call_id field.\\n\\nThe tool_call_id field is used to associate the tool call request with the\\ntool call response. This is useful in situations where a chat model is able\\nto request multiple tool calls in parallel.',\n",
       "   'properties': {'content': {'anyOf': [{'type': 'string'},\n",
       "      {'items': {'anyOf': [{'type': 'string'}, {'type': 'object'}]},\n",
       "       'type': 'array'}],\n",
       "     'title': 'Content'},\n",
       "    'additional_kwargs': {'title': 'Additional Kwargs', 'type': 'object'},\n",
       "    'response_metadata': {'title': 'Response Metadata', 'type': 'object'},\n",
       "    'type': {'const': 'function',\n",
       "     'default': 'function',\n",
       "     'title': 'Type',\n",
       "     'type': 'string'},\n",
       "    'name': {'title': 'Name', 'type': 'string'},\n",
       "    'id': {'anyOf': [{'type': 'string'}, {'type': 'null'}],\n",
       "     'default': None,\n",
       "     'title': 'Id'}},\n",
       "   'required': ['content', 'name'],\n",
       "   'title': 'FunctionMessage',\n",
       "   'type': 'object'},\n",
       "  'FunctionMessageChunk': {'additionalProperties': True,\n",
       "   'description': 'Function Message chunk.',\n",
       "   'properties': {'content': {'anyOf': [{'type': 'string'},\n",
       "      {'items': {'anyOf': [{'type': 'string'}, {'type': 'object'}]},\n",
       "       'type': 'array'}],\n",
       "     'title': 'Content'},\n",
       "    'additional_kwargs': {'title': 'Additional Kwargs', 'type': 'object'},\n",
       "    'response_metadata': {'title': 'Response Metadata', 'type': 'object'},\n",
       "    'type': {'const': 'FunctionMessageChunk',\n",
       "     'default': 'FunctionMessageChunk',\n",
       "     'title': 'Type',\n",
       "     'type': 'string'},\n",
       "    'name': {'title': 'Name', 'type': 'string'},\n",
       "    'id': {'anyOf': [{'type': 'string'}, {'type': 'null'}],\n",
       "     'default': None,\n",
       "     'title': 'Id'}},\n",
       "   'required': ['content', 'name'],\n",
       "   'title': 'FunctionMessageChunk',\n",
       "   'type': 'object'},\n",
       "  'HumanMessage': {'additionalProperties': True,\n",
       "   'description': 'Message from a human.\\n\\nHumanMessages are messages that are passed in from a human to the model.\\n\\nExample:\\n\\n    .. code-block:: python\\n\\n        from langchain_core.messages import HumanMessage, SystemMessage\\n\\n        messages = [\\n            SystemMessage(\\n                content=\"You are a helpful assistant! Your name is Bob.\"\\n            ),\\n            HumanMessage(\\n                content=\"What is your name?\"\\n            )\\n        ]\\n\\n        # Instantiate a chat model and invoke it with the messages\\n        model = ...\\n        print(model.invoke(messages))',\n",
       "   'properties': {'content': {'anyOf': [{'type': 'string'},\n",
       "      {'items': {'anyOf': [{'type': 'string'}, {'type': 'object'}]},\n",
       "       'type': 'array'}],\n",
       "     'title': 'Content'},\n",
       "    'additional_kwargs': {'title': 'Additional Kwargs', 'type': 'object'},\n",
       "    'response_metadata': {'title': 'Response Metadata', 'type': 'object'},\n",
       "    'type': {'const': 'human',\n",
       "     'default': 'human',\n",
       "     'title': 'Type',\n",
       "     'type': 'string'},\n",
       "    'name': {'anyOf': [{'type': 'string'}, {'type': 'null'}],\n",
       "     'default': None,\n",
       "     'title': 'Name'},\n",
       "    'id': {'anyOf': [{'type': 'string'}, {'type': 'null'}],\n",
       "     'default': None,\n",
       "     'title': 'Id'},\n",
       "    'example': {'default': False, 'title': 'Example', 'type': 'boolean'}},\n",
       "   'required': ['content'],\n",
       "   'title': 'HumanMessage',\n",
       "   'type': 'object'},\n",
       "  'HumanMessageChunk': {'additionalProperties': True,\n",
       "   'description': 'Human Message chunk.',\n",
       "   'properties': {'content': {'anyOf': [{'type': 'string'},\n",
       "      {'items': {'anyOf': [{'type': 'string'}, {'type': 'object'}]},\n",
       "       'type': 'array'}],\n",
       "     'title': 'Content'},\n",
       "    'additional_kwargs': {'title': 'Additional Kwargs', 'type': 'object'},\n",
       "    'response_metadata': {'title': 'Response Metadata', 'type': 'object'},\n",
       "    'type': {'const': 'HumanMessageChunk',\n",
       "     'default': 'HumanMessageChunk',\n",
       "     'title': 'Type',\n",
       "     'type': 'string'},\n",
       "    'name': {'anyOf': [{'type': 'string'}, {'type': 'null'}],\n",
       "     'default': None,\n",
       "     'title': 'Name'},\n",
       "    'id': {'anyOf': [{'type': 'string'}, {'type': 'null'}],\n",
       "     'default': None,\n",
       "     'title': 'Id'},\n",
       "    'example': {'default': False, 'title': 'Example', 'type': 'boolean'}},\n",
       "   'required': ['content'],\n",
       "   'title': 'HumanMessageChunk',\n",
       "   'type': 'object'},\n",
       "  'InputTokenDetails': {'description': 'Breakdown of input token counts.\\n\\nDoes *not* need to sum to full input token count. Does *not* need to have all keys.\\n\\nExample:\\n\\n    .. code-block:: python\\n\\n        {\\n            \"audio\": 10,\\n            \"cache_creation\": 200,\\n            \"cache_read\": 100,\\n        }\\n\\n.. versionadded:: 0.3.9',\n",
       "   'properties': {'audio': {'title': 'Audio', 'type': 'integer'},\n",
       "    'cache_creation': {'title': 'Cache Creation', 'type': 'integer'},\n",
       "    'cache_read': {'title': 'Cache Read', 'type': 'integer'}},\n",
       "   'title': 'InputTokenDetails',\n",
       "   'type': 'object'},\n",
       "  'InvalidToolCall': {'description': 'Allowance for errors made by LLM.\\n\\nHere we add an `error` key to surface errors made during generation\\n(e.g., invalid JSON arguments.)',\n",
       "   'properties': {'name': {'anyOf': [{'type': 'string'}, {'type': 'null'}],\n",
       "     'title': 'Name'},\n",
       "    'args': {'anyOf': [{'type': 'string'}, {'type': 'null'}], 'title': 'Args'},\n",
       "    'id': {'anyOf': [{'type': 'string'}, {'type': 'null'}], 'title': 'Id'},\n",
       "    'error': {'anyOf': [{'type': 'string'}, {'type': 'null'}],\n",
       "     'title': 'Error'},\n",
       "    'type': {'const': 'invalid_tool_call', 'title': 'Type', 'type': 'string'}},\n",
       "   'required': ['name', 'args', 'id', 'error'],\n",
       "   'title': 'InvalidToolCall',\n",
       "   'type': 'object'},\n",
       "  'OutputTokenDetails': {'description': 'Breakdown of output token counts.\\n\\nDoes *not* need to sum to full output token count. Does *not* need to have all keys.\\n\\nExample:\\n\\n    .. code-block:: python\\n\\n        {\\n            \"audio\": 10,\\n            \"reasoning\": 200,\\n        }\\n\\n.. versionadded:: 0.3.9',\n",
       "   'properties': {'audio': {'title': 'Audio', 'type': 'integer'},\n",
       "    'reasoning': {'title': 'Reasoning', 'type': 'integer'}},\n",
       "   'title': 'OutputTokenDetails',\n",
       "   'type': 'object'},\n",
       "  'SystemMessage': {'additionalProperties': True,\n",
       "   'description': 'Message for priming AI behavior.\\n\\nThe system message is usually passed in as the first of a sequence\\nof input messages.\\n\\nExample:\\n\\n    .. code-block:: python\\n\\n        from langchain_core.messages import HumanMessage, SystemMessage\\n\\n        messages = [\\n            SystemMessage(\\n                content=\"You are a helpful assistant! Your name is Bob.\"\\n            ),\\n            HumanMessage(\\n                content=\"What is your name?\"\\n            )\\n        ]\\n\\n        # Define a chat model and invoke it with the messages\\n        print(model.invoke(messages))',\n",
       "   'properties': {'content': {'anyOf': [{'type': 'string'},\n",
       "      {'items': {'anyOf': [{'type': 'string'}, {'type': 'object'}]},\n",
       "       'type': 'array'}],\n",
       "     'title': 'Content'},\n",
       "    'additional_kwargs': {'title': 'Additional Kwargs', 'type': 'object'},\n",
       "    'response_metadata': {'title': 'Response Metadata', 'type': 'object'},\n",
       "    'type': {'const': 'system',\n",
       "     'default': 'system',\n",
       "     'title': 'Type',\n",
       "     'type': 'string'},\n",
       "    'name': {'anyOf': [{'type': 'string'}, {'type': 'null'}],\n",
       "     'default': None,\n",
       "     'title': 'Name'},\n",
       "    'id': {'anyOf': [{'type': 'string'}, {'type': 'null'}],\n",
       "     'default': None,\n",
       "     'title': 'Id'}},\n",
       "   'required': ['content'],\n",
       "   'title': 'SystemMessage',\n",
       "   'type': 'object'},\n",
       "  'SystemMessageChunk': {'additionalProperties': True,\n",
       "   'description': 'System Message chunk.',\n",
       "   'properties': {'content': {'anyOf': [{'type': 'string'},\n",
       "      {'items': {'anyOf': [{'type': 'string'}, {'type': 'object'}]},\n",
       "       'type': 'array'}],\n",
       "     'title': 'Content'},\n",
       "    'additional_kwargs': {'title': 'Additional Kwargs', 'type': 'object'},\n",
       "    'response_metadata': {'title': 'Response Metadata', 'type': 'object'},\n",
       "    'type': {'const': 'SystemMessageChunk',\n",
       "     'default': 'SystemMessageChunk',\n",
       "     'title': 'Type',\n",
       "     'type': 'string'},\n",
       "    'name': {'anyOf': [{'type': 'string'}, {'type': 'null'}],\n",
       "     'default': None,\n",
       "     'title': 'Name'},\n",
       "    'id': {'anyOf': [{'type': 'string'}, {'type': 'null'}],\n",
       "     'default': None,\n",
       "     'title': 'Id'}},\n",
       "   'required': ['content'],\n",
       "   'title': 'SystemMessageChunk',\n",
       "   'type': 'object'},\n",
       "  'ToolCall': {'description': 'Represents a request to call a tool.\\n\\nExample:\\n\\n    .. code-block:: python\\n\\n        {\\n            \"name\": \"foo\",\\n            \"args\": {\"a\": 1},\\n            \"id\": \"123\"\\n        }\\n\\n    This represents a request to call the tool named \"foo\" with arguments {\"a\": 1}\\n    and an identifier of \"123\".',\n",
       "   'properties': {'name': {'title': 'Name', 'type': 'string'},\n",
       "    'args': {'title': 'Args', 'type': 'object'},\n",
       "    'id': {'anyOf': [{'type': 'string'}, {'type': 'null'}], 'title': 'Id'},\n",
       "    'type': {'const': 'tool_call', 'title': 'Type', 'type': 'string'}},\n",
       "   'required': ['name', 'args', 'id'],\n",
       "   'title': 'ToolCall',\n",
       "   'type': 'object'},\n",
       "  'ToolCallChunk': {'description': 'A chunk of a tool call (e.g., as part of a stream).\\n\\nWhen merging ToolCallChunks (e.g., via AIMessageChunk.__add__),\\nall string attributes are concatenated. Chunks are only merged if their\\nvalues of `index` are equal and not None.\\n\\nExample:\\n\\n.. code-block:: python\\n\\n    left_chunks = [ToolCallChunk(name=\"foo\", args=\\'{\"a\":\\', index=0)]\\n    right_chunks = [ToolCallChunk(name=None, args=\\'1}\\', index=0)]\\n\\n    (\\n        AIMessageChunk(content=\"\", tool_call_chunks=left_chunks)\\n        + AIMessageChunk(content=\"\", tool_call_chunks=right_chunks)\\n    ).tool_call_chunks == [ToolCallChunk(name=\\'foo\\', args=\\'{\"a\":1}\\', index=0)]',\n",
       "   'properties': {'name': {'anyOf': [{'type': 'string'}, {'type': 'null'}],\n",
       "     'title': 'Name'},\n",
       "    'args': {'anyOf': [{'type': 'string'}, {'type': 'null'}], 'title': 'Args'},\n",
       "    'id': {'anyOf': [{'type': 'string'}, {'type': 'null'}], 'title': 'Id'},\n",
       "    'index': {'anyOf': [{'type': 'integer'}, {'type': 'null'}],\n",
       "     'title': 'Index'},\n",
       "    'type': {'const': 'tool_call_chunk', 'title': 'Type', 'type': 'string'}},\n",
       "   'required': ['name', 'args', 'id', 'index'],\n",
       "   'title': 'ToolCallChunk',\n",
       "   'type': 'object'},\n",
       "  'ToolMessage': {'additionalProperties': True,\n",
       "   'description': 'Message for passing the result of executing a tool back to a model.\\n\\nToolMessages contain the result of a tool invocation. Typically, the result\\nis encoded inside the `content` field.\\n\\nExample: A ToolMessage representing a result of 42 from a tool call with id\\n\\n    .. code-block:: python\\n\\n        from langchain_core.messages import ToolMessage\\n\\n        ToolMessage(content=\\'42\\', tool_call_id=\\'call_Jja7J89XsjrOLA5r!MEOW!SL\\')\\n\\n\\nExample: A ToolMessage where only part of the tool output is sent to the model\\n    and the full output is passed in to artifact.\\n\\n    .. versionadded:: 0.2.17\\n\\n    .. code-block:: python\\n\\n        from langchain_core.messages import ToolMessage\\n\\n        tool_output = {\\n            \"stdout\": \"From the graph we can see that the correlation between x and y is ...\",\\n            \"stderr\": None,\\n            \"artifacts\": {\"type\": \"image\", \"base64_data\": \"/9j/4gIcSU...\"},\\n        }\\n\\n        ToolMessage(\\n            content=tool_output[\"stdout\"],\\n            artifact=tool_output,\\n            tool_call_id=\\'call_Jja7J89XsjrOLA5r!MEOW!SL\\',\\n        )\\n\\nThe tool_call_id field is used to associate the tool call request with the\\ntool call response. This is useful in situations where a chat model is able\\nto request multiple tool calls in parallel.',\n",
       "   'properties': {'content': {'anyOf': [{'type': 'string'},\n",
       "      {'items': {'anyOf': [{'type': 'string'}, {'type': 'object'}]},\n",
       "       'type': 'array'}],\n",
       "     'title': 'Content'},\n",
       "    'additional_kwargs': {'title': 'Additional Kwargs', 'type': 'object'},\n",
       "    'response_metadata': {'title': 'Response Metadata', 'type': 'object'},\n",
       "    'type': {'const': 'tool',\n",
       "     'default': 'tool',\n",
       "     'title': 'Type',\n",
       "     'type': 'string'},\n",
       "    'name': {'anyOf': [{'type': 'string'}, {'type': 'null'}],\n",
       "     'default': None,\n",
       "     'title': 'Name'},\n",
       "    'id': {'anyOf': [{'type': 'string'}, {'type': 'null'}],\n",
       "     'default': None,\n",
       "     'title': 'Id'},\n",
       "    'tool_call_id': {'title': 'Tool Call Id', 'type': 'string'},\n",
       "    'artifact': {'default': None, 'title': 'Artifact'},\n",
       "    'status': {'default': 'success',\n",
       "     'enum': ['success', 'error'],\n",
       "     'title': 'Status',\n",
       "     'type': 'string'}},\n",
       "   'required': ['content', 'tool_call_id'],\n",
       "   'title': 'ToolMessage',\n",
       "   'type': 'object'},\n",
       "  'ToolMessageChunk': {'additionalProperties': True,\n",
       "   'description': 'Tool Message chunk.',\n",
       "   'properties': {'content': {'anyOf': [{'type': 'string'},\n",
       "      {'items': {'anyOf': [{'type': 'string'}, {'type': 'object'}]},\n",
       "       'type': 'array'}],\n",
       "     'title': 'Content'},\n",
       "    'additional_kwargs': {'title': 'Additional Kwargs', 'type': 'object'},\n",
       "    'response_metadata': {'title': 'Response Metadata', 'type': 'object'},\n",
       "    'type': {'const': 'ToolMessageChunk',\n",
       "     'default': 'ToolMessageChunk',\n",
       "     'title': 'Type',\n",
       "     'type': 'string'},\n",
       "    'name': {'anyOf': [{'type': 'string'}, {'type': 'null'}],\n",
       "     'default': None,\n",
       "     'title': 'Name'},\n",
       "    'id': {'anyOf': [{'type': 'string'}, {'type': 'null'}],\n",
       "     'default': None,\n",
       "     'title': 'Id'},\n",
       "    'tool_call_id': {'title': 'Tool Call Id', 'type': 'string'},\n",
       "    'artifact': {'default': None, 'title': 'Artifact'},\n",
       "    'status': {'default': 'success',\n",
       "     'enum': ['success', 'error'],\n",
       "     'title': 'Status',\n",
       "     'type': 'string'}},\n",
       "   'required': ['content', 'tool_call_id'],\n",
       "   'title': 'ToolMessageChunk',\n",
       "   'type': 'object'},\n",
       "  'UsageMetadata': {'description': 'Usage metadata for a message, such as token counts.\\n\\nThis is a standard representation of token usage that is consistent across models.\\n\\nExample:\\n\\n    .. code-block:: python\\n\\n        {\\n            \"input_tokens\": 350,\\n            \"output_tokens\": 240,\\n            \"total_tokens\": 590,\\n            \"input_token_details\": {\\n                \"audio\": 10,\\n                \"cache_creation\": 200,\\n                \"cache_read\": 100,\\n            },\\n            \"output_token_details\": {\\n                \"audio\": 10,\\n                \"reasoning\": 200,\\n            }\\n        }\\n\\n.. versionchanged:: 0.3.9\\n\\n    Added ``input_token_details`` and ``output_token_details``.',\n",
       "   'properties': {'input_tokens': {'title': 'Input Tokens', 'type': 'integer'},\n",
       "    'output_tokens': {'title': 'Output Tokens', 'type': 'integer'},\n",
       "    'total_tokens': {'title': 'Total Tokens', 'type': 'integer'},\n",
       "    'input_token_details': {'$ref': '#/$defs/InputTokenDetails'},\n",
       "    'output_token_details': {'$ref': '#/$defs/OutputTokenDetails'}},\n",
       "   'required': ['input_tokens', 'output_tokens', 'total_tokens'],\n",
       "   'title': 'UsageMetadata',\n",
       "   'type': 'object'}},\n",
       " 'oneOf': [{'$ref': '#/$defs/AIMessage'},\n",
       "  {'$ref': '#/$defs/HumanMessage'},\n",
       "  {'$ref': '#/$defs/ChatMessage'},\n",
       "  {'$ref': '#/$defs/SystemMessage'},\n",
       "  {'$ref': '#/$defs/FunctionMessage'},\n",
       "  {'$ref': '#/$defs/ToolMessage'},\n",
       "  {'$ref': '#/$defs/AIMessageChunk'},\n",
       "  {'$ref': '#/$defs/HumanMessageChunk'},\n",
       "  {'$ref': '#/$defs/ChatMessageChunk'},\n",
       "  {'$ref': '#/$defs/SystemMessageChunk'},\n",
       "  {'$ref': '#/$defs/FunctionMessageChunk'},\n",
       "  {'$ref': '#/$defs/ToolMessageChunk'}],\n",
       " 'title': 'ChatOllamaOutput'}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain.output_schema.schema()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a973d5c",
   "metadata": {},
   "source": [
    "## Stream 流式"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "617847dc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "当然可以，下面是一个简短的关于孙悟空的故事。\n",
      "\n",
      "很久以前，在花果山水帘洞的深处，有一群猴子快乐地生活着。其中一只小猴特别聪明活泼，它的名字叫做悟空。一天，悟空和小伙伴们在山间玩耍时偶然发现了一枚神奇的仙桃，这枚仙桃有着改变命运的力量。悟空吃下了仙桃后，身体发生了变化，他的身材变得无比高大，力量也异常强大，更重要的是，他获得了七十二变的能力。\n",
      "\n",
      "后来，天庭得知了此事，认为孙悟空是凡间的叛逆者，于是派了一位天兵去捉拿悟空。然而悟空凭借自己的智慧和能力，轻松地击败了来使。天庭见状，派出了众神下界，但都被悟空一一打败。\n",
      "\n",
      "玉帝终于意识到单凭武力难以制服悟空，便决定请来如来佛祖帮忙。如来用了一只巨大的金箍将悟空定在了五指山之下，这一坐就是五百年之久。五百年后，唐僧奉命西天取经，在路过五指山时解救了孙悟空，并为他找到了保护唐僧西行的使命。\n",
      "\n",
      "从此之后，孙悟空成为了唐僧的得力助手，在经历了九九八十一难后，终于功德圆满，悟空和师傅一起取得了真经，并且也获得了封神之位。这个故事是《西游记》中的一个缩影，它讲述了悟空的成长、挑战以及最终实现自我超越的过程。\n",
      "\n",
      "希望你喜欢这个故事！如果你有兴趣了解更多关于孙悟空的故事或者有其他问题，随时告诉我哦！"
     ]
    }
   ],
   "source": [
    "for s in chain.stream({\"Topic\":\"孙悟空\"}):\n",
    "  print(s.content, end=\"\",flush=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15d078ad",
   "metadata": {},
   "source": [
    "## Batch 批处理"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1a34782f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[AIMessage(content='当然可以。下面是一个简短的关于孙悟空的故事：\\n\\n很久以前，在花果山水帘洞，有一块石头每天被甘露滋润，最终孕育出了石猴——后来的齐天大圣孙悟空。\\n\\n这石猴出世后，与猴子们一起玩耍，日子过得无忧无虑。有一天，他发现了水帘洞的美妙之处，便宣布自己成为了山中之王，并且自封为“美猴王”。\\n\\n石猴不甘于山林间的平静生活，决心寻访仙人学艺，最终来到了东海龙宫，向龙宫主人讨得了一件金箍棒作为武器。接着他又到西天拜见了菩提老祖，从老祖那里学会了长生之道以及七十二变、筋斗云等神通。\\n\\n孙悟空后来帮助唐僧取经，师徒四人历经九九八十一难，在经历了一系列冒险后，终于取得真经，并被封为“斗战胜佛”。\\n\\n这个故事不仅体现了孙悟空不畏强敌、勇往直前的精神，也反映了他机智、勇敢和幽默的性格。同时，它还隐含了对智慧与勇气的颂扬以及对于克服困难、追求真理的永恒主题。\\n\\n在《西游记》原著中还有许多关于孙悟空的故事等待着您去探索。', additional_kwargs={}, response_metadata={'model': 'qwen2.5:7b', 'created_at': '2025-04-06T03:11:44.255113Z', 'done': True, 'done_reason': 'stop', 'total_duration': 23400394666, 'load_duration': 33537708, 'prompt_eval_count': 35, 'prompt_eval_duration': 583008542, 'eval_count': 270, 'eval_duration': 22781963000, 'message': Message(role='assistant', content='', images=None, tool_calls=None)}, id='run-8cac5a91-f98e-4904-ba9c-c687478fc1f5-0', usage_metadata={'input_tokens': 35, 'output_tokens': 270, 'total_tokens': 305}),\n",
       " AIMessage(content='当然可以。猪八戒，又称为悟能或者天蓬元帅，在中国古代著名的神话小说《西游记》中扮演着重要角色。下面我将为您讲述一个与猪八戒相关的经典故事。\\n\\n### 猪八戒与唐僧的相遇\\n\\n在《西游记》的故事中，唐僧师徒四人取经的旅程开始于唐僧被观音菩萨点化前往东土大唐寻找真经的过程。在此之前，猪八戒原是天宫中的天蓬元帅，在一次醉酒之后乱了军纪，被贬下凡间转世为一个长着六耳和六手的野猪妖。\\n\\n在西行取经的路上，唐僧与孙悟空、沙和尚一同跋山涉水。一天，他们路过一片村庄，村民们告诉他们这里经常有妖怪出没，常常伤害百姓。这时，猪八戒从远处走来，他因之前被贬下凡间时贪吃受罚，在人间做了一段时间的野猪精。他自称为“卷帘大将”，并且提出愿意保护唐僧一行人。于是，他们结伴而行。\\n\\n### 大战红孩儿\\n\\n在取经的路上，他们遇到了火焰山，这是一片由红孩儿（又称圣婴大王）所引起的火焰之地，无法通过。猪八戒建议孙悟空去请观音菩萨帮忙。观音菩萨了解了情况后，决定亲自出面解决这个问题。\\n\\n红孩儿非常聪明，他使用火云洞的烈焰和变化之术来对抗唐僧师徒。孙悟空几次都被困在火焰之中。这时，猪八戒挺身而出，用他的九齿钉耙与红孩儿战斗。虽然他力大无比，但面对红孩儿的变化多端还是有些吃力。\\n\\n最终，在观音菩萨的帮助下，他们找到了破除这场灾难的方法——将扇子吹灭了火焰山上的大火，并且收服了红孩儿作为观音菩萨的弟子。\\n\\n### 猪八戒的改过自新\\n\\n经过这一系列事件之后，猪八戒开始意识到自己的错误，并决心改正。在后来的取经路上，他成为了唐僧最忠诚、最可靠的徒弟之一。他学会了控制自己的欲望和脾气，也变得更有耐心和智慧。最终，在取经成功后，他也获得了封赏，成了一位天上的神仙。\\n\\n这个故事体现了猪八戒从一个贪吃懒散的妖怪转变成了一个愿意保护师父并为西行大业作出贡献的好徒弟的过程。通过这一过程，他的形象从最初的反派逐渐变成了团队中不可或缺的一员。', additional_kwargs={}, response_metadata={'model': 'qwen2.5:7b', 'created_at': '2025-04-06T03:12:00.23614Z', 'done': True, 'done_reason': 'stop', 'total_duration': 39381479459, 'load_duration': 33668792, 'prompt_eval_count': 37, 'prompt_eval_duration': 994937458, 'eval_count': 548, 'eval_duration': 38350603375, 'message': Message(role='assistant', content='', images=None, tool_calls=None)}, id='run-e88a662c-a74e-4cc4-aeeb-003f9af0f197-0', usage_metadata={'input_tokens': 37, 'output_tokens': 548, 'total_tokens': 585})]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain.batch(\n",
    "  [\n",
    "    {\"Topic\":\"孙悟空\"},\n",
    "    {\"Topic\":\"猪八戒\"}\n",
    "  ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74ff80df",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[AIMessage(content='当然可以，下面是一个温馨的小故事：\\n\\n在一个宁静的小镇上，有一只名叫“橘子”的小猫咪。橘子有着一身柔软的橘黄色毛发和一对灵动的大眼睛，它是小镇上的明星宠物。\\n\\n橘子原本属于一个善良的家庭，但因为搬家的原因被主人遗弃了。它孤零零地待在小镇的一处空地上，每天只能依靠自己去寻找食物和庇护所。但它从不放弃希望，总是乐观地看着天空，梦想着有一天能找到新的家。\\n\\n一天，当小镇举办了一场宠物义演，橘子决定偷偷溜进去参加。它的表演非常精彩，用敏捷的动作和灵活的身手赢得了观众们的掌声与欢呼。演出结束时，一个年轻的女孩被橘子的勇敢和魅力所吸引，她走近橘子，轻轻地抱起它。\\n\\n这个女孩名叫小雨，她决定收养这只坚强的小猫咪。从此以后，橘子不再孤独，每天都有温暖的食物、舒适的床铺以及一个充满爱的家庭。而小雨也因为有了橘子，生活变得更加丰富多彩。每当夜幕降临，橘子都会依偎在小雨的身旁，讲述它过去的经历和现在的新家。\\n\\n这个故事告诉我们：无论遇到多大的困难，只要我们保持乐观的心态，并且勇敢地去追求自己想要的生活，总有一天会找到属于自己的幸福。', additional_kwargs={}, response_metadata={'model': 'qwen2.5:7b', 'created_at': '2025-04-06T03:14:06.292858Z', 'done': True, 'done_reason': 'stop', 'total_duration': 26284176042, 'load_duration': 32607625, 'prompt_eval_count': 35, 'prompt_eval_duration': 661924208, 'eval_count': 282, 'eval_duration': 25587699708, 'message': Message(role='assistant', content='', images=None, tool_calls=None)}, id='run-7f062cdf-e6fe-4d5a-a2c0-ba34c6b99a20-0', usage_metadata={'input_tokens': 35, 'output_tokens': 282, 'total_tokens': 317}),\n",
       " AIMessage(content='当然可以，下面是一个温馨感人的狗的故事。\\n\\n在一个偏远的山村，住着一位名叫小明的年轻人和他的老伴。他们以养鸡和卖鸡蛋为生，日子虽不富裕但也过得平静而简单。村里的人都说他们家里有一只特别聪明而且忠诚的老黄狗——大黄，它不仅是家里的守护者，也是他们的忠实伙伴。\\n\\n有一天，村里突然来了一个流浪的小女孩。她叫小琳，因为家里太穷了，不得不和爷爷奶奶一起四处奔波寻找食物。她流着泪，饿得几乎走不动路，被好心的村民们带回了村。当小女孩出现在小明家门前时，大黄立刻发现了这个陌生又疲惫的身影，它先是警惕地围着小女孩转了几圈，随后用鼻子轻轻地碰触着她的手，似乎在寻求安慰。\\n\\n看到小女孩无助的样子，小明决定收养她，让小女孩暂时住在他们家里。起初，小琳对这个突然出现在自己生命中的大家庭感到非常惊讶和感激。而大黄则成为了她最好的朋友，每次放学回家，大黄都会在家门口等候着，然后用它那温柔的眼神和友好的摇尾来迎接她。\\n\\n随着时间的推移，大黄不仅教会了小琳如何更好地与人相处，还带着她去探索村里的每一个角落，让原本胆怯的小琳慢慢变得开朗起来。他们一起在田野里追逐蝴蝶、在溪边捉鱼，在夜晚的大树下数星星。这些美好的回忆成了小琳生命中最珍贵的记忆。\\n\\n但好景不长，小女孩的爷爷奶奶最终找到了她，并提出要接她回去。分别那天，所有人都泣不成声。大黄也依依不舍地围着小琳转圈，用它那充满感情的眼神看着小琳，似乎在告诉她：“我会一直等你回来。”而小明和小琳相约好，长大后一定要再见面。\\n\\n几年后，当小女孩再次踏上回村子的路时，大黄果然守在村口等候。这次，他们一起度过了更多快乐的日子，直到大黄年老体衰，在小明的陪伴下安详地离开了这个世界。但大黄留给他们的爱与忠诚，成为了村里流传的美好故事。\\n\\n这个故事虽然是虚构的，但它传达了关于友谊、忠诚和关爱的信息。希望它能够温暖你的心灵。', additional_kwargs={}, response_metadata={'model': 'qwen2.5:7b', 'created_at': '2025-04-06T03:14:26.479263Z', 'done': True, 'done_reason': 'stop', 'total_duration': 46481098542, 'load_duration': 32652542, 'prompt_eval_count': 35, 'prompt_eval_duration': 662473125, 'eval_count': 488, 'eval_duration': 45783919583, 'message': Message(role='assistant', content='', images=None, tool_calls=None)}, id='run-bcf8e217-43bc-49a4-91cb-688e265b786d-0', usage_metadata={'input_tokens': 35, 'output_tokens': 488, 'total_tokens': 523}),\n",
       " AIMessage(content='当然可以。下面是一个温馨的小故事，讲述了一只聪明的猪。\\n\\n在一片绿油油的田野上，住着一只名叫“噜噜”的小猪。噜噜和其他的猪一样，喜欢吃、爱睡觉，但它有一个特别之处——它非常喜欢思考和解决问题。\\n\\n一天清晨，噜噜醒来时发现它的饲料桶空了。它抬头望向高高的树顶，看到了一串紫色的葡萄挂在树上，看起来非常诱人。“我要吃那些葡萄！”噜噜心想。可是，葡萄太高了，用鼻子够不着，用脚也够不着。\\n\\n噜噜并没有放弃，而是开始动脑筋思考如何才能吃到那串葡萄。它在田野里转了一圈，发现不远处有一个小小的木箱子，便决定将这个箱子搬过来放在树下。然后，它坐在箱子上，伸长了脖子还是不够高；于是，噜噜又找来一根长长的树枝，把树枝绑在一棵树上作为杠杆，另一端顶住箱子的一角，借助箱子的力把树枝抬了起来，这样就形成了一个简易的“葡萄摘取器”。\\n\\n最终，噜噜成功地摘到了那串紫色的葡萄。它一边享受着美味的果实，一边高兴地笑了。\\n\\n从此以后，“噜噜”成了田野上的一只聪明又可爱的猪，而它的故事也成为了其他动物们茶余饭后的佳话。\\n\\n这个故事告诉我们：面对困难和挑战时，不要放弃，多动脑筋想办法，就一定能够找到解决问题的方法。', additional_kwargs={}, response_metadata={'model': 'qwen2.5:7b', 'created_at': '2025-04-06T03:14:32.978101Z', 'done': True, 'done_reason': 'stop', 'total_duration': 26704168541, 'load_duration': 11680583, 'prompt_eval_count': 35, 'prompt_eval_duration': 440232500, 'eval_count': 317, 'eval_duration': 26250552042, 'message': Message(role='assistant', content='', images=None, tool_calls=None)}, id='run-14d6ac7b-b8e5-4ff2-a8b6-0147c833ab6a-0', usage_metadata={'input_tokens': 35, 'output_tokens': 317, 'total_tokens': 352})]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 使用 max_concurrency 控制并发数\n",
    "chain.batch(\n",
    "  [\n",
    "    {\"Topic\":\"猫\"},\n",
    "    {\"Topic\":\"狗\"},\n",
    "    {\"Topic\":\"猪\"},\n",
    "  ],\n",
    "  config={\"max_concurrency\":5},\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "506b1455",
   "metadata": {},
   "source": [
    "## 异步\n",
    "异步是一种编程方式，允许程序在等待某些操作完成时继续执行其他任务，而不会阻塞整个程序的运行。这种方式通常用于处理 I/O 操作（如网络请求、文件读写）或其他耗时任务，从而提高程序的效率和响应速度。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1b797c6",
   "metadata": {},
   "source": [
    "## Async Stream 异步流"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b064536",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "当然可以，下面是一个简短的、适合小朋友听的故事：\n",
      "\n",
      "很久以前，在中国有一个神通广大的猴王——孙悟空。他原本是花果山上的石猴，因为发现了水帘洞，成为了猴群的领袖。\n",
      "\n",
      "有一天，悟空在云游四方时，遇到了唐僧和猪八戒、沙僧三位旅行者。他们遇到了许多妖怪的阻碍，而孙悟空则凭借自己的智慧和力量，一一战胜了它们。猪八戒常常因为贪吃懒做而惹出麻烦，而沙僧总是默默无闻地帮助大家。\n",
      "\n",
      "在取经的路上，悟空遇到了很多挑战。有一次，他们被一个名叫红孩儿的小妖精捉住了。红孩儿使用的是火云之术，让火焰熊熊燃烧。孙悟空想尽办法都无法救出唐僧，后来他向观音菩萨求助，在她的帮助下才成功地制服了红孩儿。\n",
      "\n",
      "经过无数的艰难险阻，悟空和三位徒弟终于完成了取经的任务。他们不仅得到了佛祖的认可，也成为了传说中的英雄。从此以后，孙悟空便在天上被封为“斗战胜佛”，开始了新的生活。\n",
      "\n",
      "这个故事讲述了勇敢、智慧与友情的重要性，同时也告诉人们面对困难时不要放弃希望，总会有办法解决的。"
     ]
    }
   ],
   "source": [
    "# 这是一个异步 for 循环，使用了 Python 的 async/await 语法。\n",
    "# 1. `async` 关键字表明这是一个异步操作，适用于需要等待 I/O 操作完成的场景，例如网络请求或文件读写。\n",
    "# 2. `async for` 用于异步迭代，表示 `chain.astream({\"Topic\":\"孙悟空\"})` 是一个异步可迭代对象（\n",
    "#                如异步生成器或实现了异步迭代协议的对象）。\n",
    "# 3. 在每次迭代中，代码会等待异步操作完成，然后获取下一个值。\n",
    "# 4. `print(s.content, end=\"\", flush=True)` 打印每次迭代返回的内容，`end=\"\"` 表示不换行，\n",
    "#                                           `flush=True` 确保输出立即刷新到终端。\n",
    "async for s in chain.astream({\"Topic\":\"孙悟空\"}):\n",
    "  print(s.content, end=\"\", flush=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a0fb9a7",
   "metadata": {},
   "source": [
    "Async Invoke"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6045263a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='当然可以。关于孙悟空，有无数精彩的传说故事，这里我为你简述一个大家耳熟能详的经典故事——《三打白骨精》。\\n\\n很久以前，在花果山上，孙悟空作为齐天大圣得到了如来佛祖的法力，拥有了七十二变、筋斗云等超凡能力。他不满足于在山上的自在生活，决定下界寻找更多的挑战和冒险。\\n\\n一天，唐僧和他的徒弟沙悟净、猪八戒一同西行取经。他们路过了一片荒凉之地，突然，一群饿狼来袭。孙悟空一展身手，用金箍棒轻松解决了这些妖魔。之后不久，一个老妇人敲锣打鼓求救，说是被恶狼围攻，她请求唐僧救命。善良的唐僧没有多想就收留了她。\\n\\n然而，这却是一场精心设计的陷阱。原来，这只是一只变化为老妇人的白骨精。孙悟空一眼识破了她的诡计，但唐僧并未相信孙悟空的话，反而责怪他滥杀无辜。第一次打斗以失败告终。\\n\\n不久后，白骨精再次化身为一位少女出现，企图诱骗唐僧离开。这一次，孙悟空凭借敏锐的洞察力和强大的力量，一棒将其击退。但唐僧依旧不信任孙悟空，并驱逐了悟空，自己前往山下向观音菩萨求助。\\n\\n白骨精见计谋未得逞，再次化身为老妇人，但这次她被彻底打穿了肉身，露出了原形。悟空最终用金箍棒一棍将她打死，救下了唐僧。\\n\\n从此之后，孙悟空和唐僧师徒四人共同经历了更多的磨难与挑战，在取经的道路上结下了深厚的友谊，并且一同克服了一个又一个难关，直到他们到达西天取得了真经。\\n\\n这个故事体现了孙悟空机智勇敢、不畏强敌的精神，同时也展示了唐僧虽有缺点但最终能够改正错误、与悟空和解的情节。', additional_kwargs={}, response_metadata={'model': 'qwen2.5:7b', 'created_at': '2025-04-06T03:20:40.359426Z', 'done': True, 'done_reason': 'stop', 'total_duration': 25107131708, 'load_duration': 26289958, 'prompt_eval_count': 35, 'prompt_eval_duration': 590741333, 'eval_count': 430, 'eval_duration': 24486937125, 'message': Message(role='assistant', content='', images=None, tool_calls=None)}, id='run-62045b7c-a259-47fb-ba50-8d0b26e5501c-0', usage_metadata={'input_tokens': 35, 'output_tokens': 430, 'total_tokens': 465})"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# await：表示这是一个异步操作，代码会等待 ainvoke 方法完成后再继续执行。\n",
    "await chain.ainvoke({\"Topic\":\"孙悟空\"})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f52c8b7b",
   "metadata": {},
   "source": [
    "Async Batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "f2c57b72",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[AIMessage(content='当然可以，下面是一个温馨的小故事：\\n\\n从前，在一座宁静的小镇上，住着一只名叫米娜的猫咪。米娜有着一身柔软的灰色毛发和一双明亮的大眼睛，她住在一家充满爱的家庭里。\\n\\n这家人的父亲是一位画家，母亲则是一名作家，而米娜则是他们之间的小小纽带。每天早晨，当阳光透过窗户洒进房间时，米娜会跳到爸爸的工作台上，用它那小小的爪子轻轻地按压画板上的颜料盘，制造出各种有趣的图案。爸爸经常为此忍俊不禁，笑咪咪地告诉妈妈：“看，这是米娜的作品！”\\n\\n随着时间的流逝，米娜长大了，开始喜欢上了冒险。有一天，她决定去探索小镇周围的森林。在那里，她遇到了一只友好的小松鼠和一条温柔的小狗。尽管他们来自不同的世界，但他们很快成为了好朋友。\\n\\n在这次探险中，有一次，天气突然变得恶劣起来，狂风呼啸，雷声隆隆。正当大家都感到害怕的时候，是米娜用她那敏锐的直觉发现了附近的一棵大树下的一个小洞穴。最终，他们躲过了这场突如其来的暴风雨，并且在温暖的小洞穴里度过了一个美好的夜晚。\\n\\n当早晨的第一缕阳光照进洞穴时，他们感激地向米娜道别，并继续他们的旅程。而米娜则回到了自己的小窝中，但她的心里却充满了勇气和友谊的喜悦。从那以后，她不仅更加勇敢了，而且也明白了友情的价值。\\n\\n这个故事告诉我们，无论年龄多大、身在何处，我们都应该勇敢探索未知的世界，同时也要珍惜身边的友谊。', additional_kwargs={}, response_metadata={'model': 'qwen2.5:7b', 'created_at': '2025-04-06T03:22:55.977603Z', 'done': True, 'done_reason': 'stop', 'total_duration': 31401463292, 'load_duration': 33097667, 'prompt_eval_count': 35, 'prompt_eval_duration': 882262292, 'eval_count': 345, 'eval_duration': 30484449875, 'message': Message(role='assistant', content='', images=None, tool_calls=None)}, id='run-2910a045-4405-4a3a-8697-f3e820067387-0', usage_metadata={'input_tokens': 35, 'output_tokens': 345, 'total_tokens': 380}),\n",
       " AIMessage(content='当然可以。这是一个温馨的小故事，关于一只聪明的狗和它与主人之间的深厚情谊。\\n\\n---\\n\\n在一个小镇上，住着一位年轻的画家叫林浩。他平时最喜欢做的事情就是在画布上描绘各种动物，尤其是那条陪伴在他身边的忠诚伙伴——拉布拉多犬豆豆。\\n\\n豆豆是一只非常聪明、活泼又充满爱心的狗。每天早晨，当第一缕阳光照进林浩的小屋时，豆豆就会用它那特有的方式叫醒主人：轻巧地跳上床边，摇着尾巴，发出“汪汪”的声音。而林浩则会被这温暖的声音所唤醒。\\n\\n在林浩画画的时候，豆豆会安静地待在他的脚边，偶尔抬头看看画布上的每一笔一划；每当林浩想要出去散步时，豆豆总是紧紧跟随在他身边，似乎也在享受着外面的空气和风景。有时候，他们会在公园里度过整个下午，一起追逐蝴蝶、捡拾落叶。\\n\\n时间长了，林浩发现，豆豆似乎对他的画作非常感兴趣。每天晚上回去后，豆豆总爱坐在窗边，看着林浩画画的身影和窗外的城市夜景。而每当林浩完成一幅作品时，都会把画作放在咖啡桌上，然后牵着豆豆的手一起去客厅观看。\\n\\n有一天，林浩决定为豆豆画一幅肖像。他细心地观察着豆豆的样子：那双温柔的眼睛、长长的尾巴以及毛茸茸的身体，每一处都充满了爱与忠诚的光芒。当这幅画终于完成的时候，林浩把它挂在了墙上，并在旁边写了一行字：“我的朋友——豆豆”。\\n\\n从那天起，每当有人问起林浩，他的作品中为什么会常常出现动物主题时，他都会笑而不语地指向墙上的那幅肖像，说：“这是我家的守护者。”而每次看到这幅画，豆豆就会摇着尾巴，仿佛在告诉林浩：“谢谢你，我的主人。”\\n\\n这个故事虽然简单，但却充满了温馨与爱意。它告诉我们，无论多么简单的陪伴或付出，在对方心中都有着不可替代的位置。\\n\\n---\\n\\n希望您喜欢这个关于狗的故事！如果有其他想要听的故事类型或者具体内容，请随时告诉我。', additional_kwargs={}, response_metadata={'model': 'qwen2.5:7b', 'created_at': '2025-04-06T03:23:03.729133Z', 'done': True, 'done_reason': 'stop', 'total_duration': 39153400625, 'load_duration': 33567666, 'prompt_eval_count': 35, 'prompt_eval_duration': 882786041, 'eval_count': 467, 'eval_duration': 38235561334, 'message': Message(role='assistant', content='', images=None, tool_calls=None)}, id='run-480609ab-1886-4c10-8547-d254d6831ab6-0', usage_metadata={'input_tokens': 35, 'output_tokens': 467, 'total_tokens': 502})]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "await chain.abatch(\n",
    "  [\n",
    "    {\"Topic\":\"猫\"},\n",
    "    {\"Topic\":\"狗\"},\n",
    "  ],\n",
    "  config={\"max_concurrency\":5},\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2effc87",
   "metadata": {},
   "source": [
    "# 异步获取中间步骤"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "3ea3972b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "\n",
    "from langchain_core.runnables import RunnablePassthrough\n",
    "from langchain_ollama.chat_models import ChatOllama\n",
    "from langchain_ollama.embeddings import OllamaEmbeddings\n",
    "from langchain.vectorstores import FAISS\n",
    "\n",
    "# 使用 FAISS 创建一个向量存储，存储文本及其对应的嵌入\n",
    "vectorstore = FAISS.from_texts(\n",
    "  [\"\"\"狸花猫是一种小型的猫咪\"\"\"],  # 输入文本\n",
    "  embedding=OllamaEmbeddings(model=\"bge-m3\")  # 使用 OllamaEmbeddings 生成嵌入\n",
    ")\n",
    "\n",
    "# 将向量存储转换为检索器，用于从存储中检索相关内容\n",
    "retriever = vectorstore.as_retriever()\n",
    "\n",
    "# 定义一个模板，用于生成提示信息\n",
    "template = \"\"\"基于下面的上下文来回答问题:\n",
    "{context}\n",
    "Question:{question}\n",
    "\"\"\"\n",
    "\n",
    "# 使用模板创建一个聊天提示模板\n",
    "prompt = ChatPromptTemplate.from_template(template)\n",
    "\n",
    "# 定义一个 ChatOllama 模型，用于生成回答\n",
    "model = ChatOllama(model=\"qwen2.5:7b\")\n",
    "\n",
    "retrieval_chain = (\n",
    "  # 定义一个字典，其中 \"context\" 使用 retriever 检索器，\"question\" 使用 RunnablePassthrough 直接传递输入\n",
    "  {\"context\": retriever, \"question\": RunnablePassthrough()}\n",
    "  # 将上述字典作为输入，传递给 prompt 模板，用于生成提示\n",
    "  | prompt\n",
    "  # 将生成的提示传递给模型（ChatOllama）进行推理\n",
    "  | model\n",
    "  # 将模型的输出通过 StrOutputParser 解析为字符串\n",
    "  | StrOutputParser()\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d470d6ed",
   "metadata": {},
   "source": [
    "#### 使用 astream_log"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "ca61e28c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------------\n",
      "RunLogPatch({'op': 'replace',\n",
      "  'path': '',\n",
      "  'value': {'final_output': None,\n",
      "            'id': '841e0798-74e2-465f-bb9e-1bc51b4ee437',\n",
      "            'logs': {},\n",
      "            'name': 'RunnableSequence',\n",
      "            'streamed_output': [],\n",
      "            'type': 'chain'}})\n",
      "------------------------------------------------\n",
      "RunLogPatch({'op': 'add', 'path': '/streamed_output/-', 'value': '狸'},\n",
      " {'op': 'replace', 'path': '/final_output', 'value': '狸'})\n",
      "------------------------------------------------\n",
      "RunLogPatch({'op': 'add', 'path': '/streamed_output/-', 'value': '花'},\n",
      " {'op': 'replace', 'path': '/final_output', 'value': '狸花'})\n",
      "------------------------------------------------\n",
      "RunLogPatch({'op': 'add', 'path': '/streamed_output/-', 'value': '猫'},\n",
      " {'op': 'replace', 'path': '/final_output', 'value': '狸花猫'})\n",
      "------------------------------------------------\n",
      "RunLogPatch({'op': 'add', 'path': '/streamed_output/-', 'value': '是一种'},\n",
      " {'op': 'replace', 'path': '/final_output', 'value': '狸花猫是一种'})\n",
      "------------------------------------------------\n",
      "RunLogPatch({'op': 'add', 'path': '/streamed_output/-', 'value': '小型'},\n",
      " {'op': 'replace', 'path': '/final_output', 'value': '狸花猫是一种小型'})\n",
      "------------------------------------------------\n",
      "RunLogPatch({'op': 'add', 'path': '/streamed_output/-', 'value': '的'},\n",
      " {'op': 'replace', 'path': '/final_output', 'value': '狸花猫是一种小型的'})\n",
      "------------------------------------------------\n",
      "RunLogPatch({'op': 'add', 'path': '/streamed_output/-', 'value': '猫咪'},\n",
      " {'op': 'replace', 'path': '/final_output', 'value': '狸花猫是一种小型的猫咪'})\n",
      "------------------------------------------------\n",
      "RunLogPatch({'op': 'add', 'path': '/streamed_output/-', 'value': '。'},\n",
      " {'op': 'replace', 'path': '/final_output', 'value': '狸花猫是一种小型的猫咪。'})\n",
      "------------------------------------------------\n",
      "RunLogPatch({'op': 'add', 'path': '/streamed_output/-', 'value': ''})\n"
     ]
    }
   ],
   "source": [
    "async for chunk in retrieval_chain.astream_log(\n",
    "  \"狸花猫是什么？\", include_names=[\"Docs\"]\n",
    "):\n",
    "  print(\"-\" * 48)\n",
    "  print(chunk)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae7ea7a4",
   "metadata": {},
   "source": [
    "## 并行支持\n",
    "- Runnables RunnableParalle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4c0c81f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.runnables import RunnableParallel\n",
    "\n",
    "chain1 = ChatPromptTemplate.from_template(\"给我讲一个关于{topic}的笑话\") | model\n",
    "chain2 = ChatPromptTemplate.from_template(\"写两行关于{topic}的诗歌\") | model\n",
    "\n",
    "combine_chain12 = RunnableParallel(joke=chain1,poem=chain2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "cb8f05ac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 25.9 ms, sys: 6.53 ms, total: 32.4 ms\n",
      "Wall time: 3.56 s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "AIMessage(content='当然可以，这里有一个轻松幽默的小故事：\\n\\n为什么柳树要请理发师？\\n\\n因为它想把自己的枝条修剪得像“吊”一样整齐！（这里的“吊”谐音“条”，是柳树枝的意思）\\n\\n希望这个小笑话能给你带来一丝欢乐！', additional_kwargs={}, response_metadata={'model': 'qwen2.5:7b', 'created_at': '2025-04-06T03:58:39.576609Z', 'done': True, 'done_reason': 'stop', 'total_duration': 3551639084, 'load_duration': 27406542, 'prompt_eval_count': 37, 'prompt_eval_duration': 428584000, 'eval_count': 58, 'eval_duration': 3094075750, 'message': Message(role='assistant', content='', images=None, tool_calls=None)}, id='run-ba184868-8849-48e6-a086-194f6f9c43bf-0', usage_metadata={'input_tokens': 37, 'output_tokens': 58, 'total_tokens': 95})"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "chain1.invoke({\"topic\":\"柳树\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "5cb7fb35",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 8.99 ms, sys: 3.03 ms, total: 12 ms\n",
      "Wall time: 1.03 s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "AIMessage(content='绿丝垂拂映清水，微风吹过舞柳姿。', additional_kwargs={}, response_metadata={'model': 'qwen2.5:7b', 'created_at': '2025-04-06T03:58:43.557591Z', 'done': True, 'done_reason': 'stop', 'total_duration': 1019335375, 'load_duration': 25405958, 'prompt_eval_count': 37, 'prompt_eval_duration': 232163084, 'eval_count': 15, 'eval_duration': 759591041, 'message': Message(role='assistant', content='', images=None, tool_calls=None)}, id='run-31ec0a13-d3d5-43e9-b8bd-69ad5fb142b2-0', usage_metadata={'input_tokens': 37, 'output_tokens': 15, 'total_tokens': 52})"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "chain2.invoke({\"topic\":\"柳树\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "55882ab0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 40.6 ms, sys: 7.43 ms, total: 48 ms\n",
      "Wall time: 4.11 s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'joke': AIMessage(content='当然可以！这里有一个关于柳树的轻松幽默小故事：\\n\\n为什么柳树不能当记者？\\n\\n因为它总是“垂”听别人的事情，却从不主动出击去获取信息！\\n\\n希望这个小小的笑话能给你带来一些乐趣！如果你有其他需求或想要更多笑话，请随时告诉我。', additional_kwargs={}, response_metadata={'model': 'qwen2.5:7b', 'created_at': '2025-04-06T03:58:51.557583Z', 'done': True, 'done_reason': 'stop', 'total_duration': 4099679208, 'load_duration': 27585917, 'prompt_eval_count': 37, 'prompt_eval_duration': 368891417, 'eval_count': 62, 'eval_duration': 3701195833, 'message': Message(role='assistant', content='', images=None, tool_calls=None)}, id='run-b9f05057-4de5-439e-9b94-ac849ed7726d-0', usage_metadata={'input_tokens': 37, 'output_tokens': 62, 'total_tokens': 99}),\n",
       " 'poem': AIMessage(content='碧波轻漾绿丝垂，风送柔情拂岸时。', additional_kwargs={}, response_metadata={'model': 'qwen2.5:7b', 'created_at': '2025-04-06T03:58:49.007966Z', 'done': True, 'done_reason': 'stop', 'total_duration': 1549075125, 'load_duration': 26501958, 'prompt_eval_count': 37, 'prompt_eval_duration': 232507584, 'eval_count': 17, 'eval_duration': 1289049666, 'message': Message(role='assistant', content='', images=None, tool_calls=None)}, id='run-970ce57a-31c5-4cd6-9437-bdb820aa216d-0', usage_metadata={'input_tokens': 37, 'output_tokens': 17, 'total_tokens': 54})}"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "combine_chain12.invoke({\"topic\":\"柳树\"})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61614118",
   "metadata": {},
   "source": [
    "并行批处理，适用于大量的生成"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "c26cc9f6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 41.9 ms, sys: 7.79 ms, total: 49.7 ms\n",
      "Wall time: 5.93 s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[AIMessage(content='当然可以，这里有一个简单的猫咪笑话：\\n\\n为什么猫不能上网？\\n\\n因为它们总是点击“捕鼠器”而不是“链接”。', additional_kwargs={}, response_metadata={'model': 'qwen2.5:7b', 'created_at': '2025-04-06T04:00:41.406619Z', 'done': True, 'done_reason': 'stop', 'total_duration': 3378203542, 'load_duration': 87689875, 'prompt_eval_count': 36, 'prompt_eval_duration': 1048610208, 'eval_count': 28, 'eval_duration': 2240622709, 'message': Message(role='assistant', content='', images=None, tool_calls=None)}, id='run-13dcc5fa-0658-45de-ad87-6ce805f0b0e8-0', usage_metadata={'input_tokens': 36, 'output_tokens': 28, 'total_tokens': 64}),\n",
       " AIMessage(content='当然可以！这里有一个关于狗的小笑话：\\n\\n为什么小狗过马路前会先停下来闻一闻？\\n\\n因为它想知道，这条路上有没有别的狗狗今天也出门散步了。如果有的话，它最好等到它们走远一点，否则可能会被卷入一场激动人心的追逐游戏中呢！\\n\\n希望这个小笑话能让您和您的爱犬会心一笑！', additional_kwargs={}, response_metadata={'model': 'qwen2.5:7b', 'created_at': '2025-04-06T04:00:43.946638Z', 'done': True, 'done_reason': 'stop', 'total_duration': 5916802750, 'load_duration': 86069166, 'prompt_eval_count': 41, 'prompt_eval_duration': 801846917, 'eval_count': 76, 'eval_duration': 5028024500, 'message': Message(role='assistant', content='', images=None, tool_calls=None)}, id='run-5b6105d1-aba8-4275-baca-945b9c1d187b-0', usage_metadata={'input_tokens': 41, 'output_tokens': 76, 'total_tokens': 117})]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "chain1.batch([{\"topic\":\"猫\"},{\"topic\",\"狗\"}])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "f5f9bacb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 39.5 ms, sys: 8.62 ms, total: 48.1 ms\n",
      "Wall time: 5.39 s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'joke': AIMessage(content='当然可以，这里有一个简单的猫的笑话：\\n\\n为什么猫咪不喜欢上网？\\n\\n因为它们总是在点击“刷新”！', additional_kwargs={}, response_metadata={'model': 'qwen2.5:7b', 'created_at': '2025-04-06T04:01:11.961355Z', 'done': True, 'done_reason': 'stop', 'total_duration': 3654601959, 'load_duration': 29226292, 'prompt_eval_count': 36, 'prompt_eval_duration': 350326333, 'eval_count': 25, 'eval_duration': 3273588250, 'message': Message(role='assistant', content='', images=None, tool_calls=None)}, id='run-31d4ac6a-bd09-4ae5-849f-9671db8078b2-0', usage_metadata={'input_tokens': 36, 'output_tokens': 25, 'total_tokens': 61}),\n",
       "  'poem': AIMessage(content='毛绒轻步悄无声，夜半偷光梦中行。', additional_kwargs={}, response_metadata={'model': 'qwen2.5:7b', 'created_at': '2025-04-06T04:01:11.199683Z', 'done': True, 'done_reason': 'stop', 'total_duration': 2891097458, 'load_duration': 29470958, 'prompt_eval_count': 36, 'prompt_eval_duration': 348173583, 'eval_count': 16, 'eval_duration': 2512665042, 'message': Message(role='assistant', content='', images=None, tool_calls=None)}, id='run-99905ddd-96c6-4e10-855b-79febe9dd155-0', usage_metadata={'input_tokens': 36, 'output_tokens': 16, 'total_tokens': 52})},\n",
       " {'joke': AIMessage(content='当然可以，这是一则关于“狗”的小幽默：\\n\\n为什么小狗不喜欢上网？\\n\\n因为它担心遇到“汪星人”！（注：这里的“汪星人”是网络流行语，用来指代狗狗。）\\n\\n希望你笑了呢！', additional_kwargs={}, response_metadata={'model': 'qwen2.5:7b', 'created_at': '2025-04-06T04:01:13.680518Z', 'done': True, 'done_reason': 'stop', 'total_duration': 5372769041, 'load_duration': 28853250, 'prompt_eval_count': 41, 'prompt_eval_duration': 350776166, 'eval_count': 53, 'eval_duration': 4991967917, 'message': Message(role='assistant', content='', images=None, tool_calls=None)}, id='run-68336980-ff61-4e21-8b07-0dc2f416c73a-0', usage_metadata={'input_tokens': 41, 'output_tokens': 53, 'total_tokens': 94}),\n",
       "  'poem': AIMessage(content='犬吠深巷中，  \\n夜话成新篇。', additional_kwargs={}, response_metadata={'model': 'qwen2.5:7b', 'created_at': '2025-04-06T04:01:10.961001Z', 'done': True, 'done_reason': 'stop', 'total_duration': 2653293959, 'load_duration': 30466917, 'prompt_eval_count': 41, 'prompt_eval_duration': 350004792, 'eval_count': 14, 'eval_duration': 2271613000, 'message': Message(role='assistant', content='', images=None, tool_calls=None)}, id='run-2913c220-11d4-4f70-89a4-7ea4abd55da3-0', usage_metadata={'input_tokens': 41, 'output_tokens': 14, 'total_tokens': 55})}]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "combine_chain12.batch([{\"topic\":\"猫\"},{\"topic\",\"狗\"}])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "rag",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
