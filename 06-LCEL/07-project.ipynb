{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "77b587bf",
   "metadata": {},
   "source": [
    "## 模型评估"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02c0983b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'reasoning': 'N', 'value': 'N', 'score': 0}\n"
     ]
    }
   ],
   "source": [
    "# 从 langchain_ollama.llms 模块中导入 OllamaLLM 类\n",
    "# 从 langchain.evaluation 模块中导入 load_evaluator 函数\n",
    "from langchain_ollama.llms import OllamaLLM\n",
    "from langchain.evaluation import load_evaluator\n",
    "\n",
    "# 创建一个 OllamaLLM 实例，指定使用的模型为 \"qwen2.5:7b\"\n",
    "llm = OllamaLLM(model=\"qwen2.5:7b\")\n",
    "\n",
    "# 使用 load_evaluator 函数加载一个评估器\n",
    "# 评估器类型为 \"criteria\"，使用的 LLM 为上面创建的 llm\n",
    "# 评估标准为 \"conciseness\"（简洁性）\n",
    "evaluator = load_evaluator(\"criteria\", llm=llm, criteria=\"conciseness\")\n",
    "\n",
    "# 使用评估器对预测结果进行评估\n",
    "# prediction 是模型生成的预测结果\n",
    "# input 是评估的输入问题\n",
    "evla_result = evaluator.evaluate_strings(\n",
    "  prediction=\"what is 2 + 2? that is an elementary question. The answer you are looking for is that two add two is four.\",  # 模型生成的预测结果\n",
    "  input=\"what is 2 + 2 ?\"  # 输入问题\n",
    ")\n",
    "\n",
    "# 打印评估结果\n",
    "# 评估结果是一个字典，包含 reasoning（推理过程）、value（是否符合标准）和 score（得分）\n",
    "print(evla_result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "daa1a249",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'reasoning': 'Y', 'value': 'Y', 'score': 1}\n"
     ]
    }
   ],
   "source": [
    "evla_result = evaluator.evaluate_strings(\n",
    "  prediction=\"4.\",\n",
    "  input=\"what is 2 + 2 ?\"\n",
    ")\n",
    "print(evla_result)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54ace260",
   "metadata": {},
   "source": [
    "### 评测标准"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7578fea6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<Criteria.CONCISENESS: 'conciseness'>,\n",
       " <Criteria.RELEVANCE: 'relevance'>,\n",
       " <Criteria.CORRECTNESS: 'correctness'>,\n",
       " <Criteria.COHERENCE: 'coherence'>,\n",
       " <Criteria.HARMFULNESS: 'harmfulness'>,\n",
       " <Criteria.MALICIOUSNESS: 'maliciousness'>,\n",
       " <Criteria.HELPFULNESS: 'helpfulness'>,\n",
       " <Criteria.CONTROVERSIALITY: 'controversiality'>,\n",
       " <Criteria.MISOGYNY: 'misogyny'>,\n",
       " <Criteria.CRIMINALITY: 'criminality'>,\n",
       " <Criteria.INSENSITIVITY: 'insensitivity'>,\n",
       " <Criteria.DEPTH: 'depth'>,\n",
       " <Criteria.CREATIVITY: 'creativity'>,\n",
       " <Criteria.DETAIL: 'detail'>]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain.evaluation import Criteria\n",
    "\n",
    "list(Criteria)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45042e38",
   "metadata": {
    "vscode": {
     "languageId": "ini"
    }
   },
   "source": [
    "以下是这些评测标准的解释：\n",
    "\n",
    "1. **CONCISENESS (简洁性)**: 评估内容是否简洁明了，是否避免了冗长或不必要的信息。\n",
    "\n",
    "2. **RELEVANCE (相关性)**: 评估内容是否与输入问题或任务相关，是否准确地回答了问题。\n",
    "\n",
    "3. **CORRECTNESS (正确性)**: 评估内容是否准确无误，是否提供了正确的信息或答案。\n",
    "\n",
    "4. **COHERENCE (连贯性)**: 评估内容是否逻辑清晰，是否具有良好的结构和连贯性。\n",
    "\n",
    "5. **HARMFULNESS (有害性)**: 评估内容是否包含可能对用户或社会有害的信息。\n",
    "\n",
    "6. **MALICIOUSNESS (恶意性)**: 评估内容是否包含恶意或有意伤害他人的信息。\n",
    "\n",
    "7. **HELPFULNESS (有用性)**: 评估内容是否对用户有帮助，是否提供了有价值的信息。\n",
    "\n",
    "8. **CONTROVERSIALITY (争议性)**: 评估内容是否可能引发争议或分歧。\n",
    "\n",
    "9. **MISOGYNY (厌女症)**: 评估内容是否包含性别歧视或厌女的倾向。\n",
    "\n",
    "10. **CRIMINALITY (犯罪性)**: 评估内容是否包含可能违法或犯罪的信息。\n",
    "\n",
    "11. **INSENSITIVITY (不敏感性)**: 评估内容是否对敏感话题缺乏同理心或表现出冷漠。\n",
    "\n",
    "12. **DEPTH (深度)**: 评估内容是否深入探讨了问题，是否提供了详细和全面的分析。\n",
    "\n",
    "13. **CREATIVITY (创造性)**: 评估内容是否展现了创造性或独特的视角。\n",
    "\n",
    "14. **DETAIL (细节性)**: 评估内容是否包含足够的细节，是否对问题进行了充分的阐述。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96c05880",
   "metadata": {},
   "source": [
    "模型比较"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "84c58f3f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: qwen2.5:7b\n",
      "Evaluation Result: {'reasoning': 'N', 'value': 'N', 'score': 0}\n",
      "--------------------------------------------------\n",
      "Model: deepscaler:latest\n",
      "Evaluation Result: {'reasoning': '<think>\\nOkay, so I need to determine if the submitted answer meets the given criteria. The task is about assessing the submission based on conciseness and another criterion. Let me break it down step by step.\\n\\nFirst, looking at the input: \"what is 2 + 2?\" That\\'s a straightforward question. The correct answer should be four because adding two and two gives us four.\\n\\nNow, checking the submission provided: \"what is 2 + 2? that is an elementary question. The answer you are looking for is that two add two is four.\" This seems to repeat the same question but adds some extra information right after the initial part. It starts with a repetition of the question and then provides an example, which isn\\'t necessary because it\\'s just repeating the problem.\\n\\nThe criteria given include conciseness: Is the submission concise and to the point? So I need to evaluate if the submission is concise. The submission includes more than just the answer; it repeats the question and adds extra information like \"that is an elementary question.\" This makes the submission longer than necessary, which might not be concise.\\n\\nI also see that the criteria mention conciseness but doesn\\'t specify other aspects. However, since the user included only this data in their query, I have to go strictly by what\\'s provided. The submission isn\\'t just a single correct answer; it includes repetition and extra information beyond the necessary part of explaining 2+2.\\n\\nTherefore, considering that the submission is not concise enough because it repeats the question and adds unnecessary details, the criteria are not met.\\n</think>\\n\\nTo assess whether the submission meets the criteria:\\n\\n1. **Conciseness**: The submission is more than just a single correct answer; it includes repetition of the question and extra information.\\n2. **Other Criteria (if any)**: Not applicable as only conciseness was mentioned.\\n\\n**Answer:**', 'value': 'N', 'score': 0}\n",
      "--------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# 定义三个模型名称\n",
    "models = [\"qwen2.5:7b\", \"deepscaler:latest\"]\n",
    "\n",
    "# 存储每个模型的评估结果\n",
    "results = {}\n",
    "\n",
    "# 遍历每个模型\n",
    "for model_name in models:\n",
    "  # 创建 OllamaLLM 实例\n",
    "  llm = OllamaLLM(model=model_name)\n",
    "\n",
    "  # 创建评估器\n",
    "  evaluator = load_evaluator(\"criteria\", llm=llm, criteria=\"conciseness\")\n",
    "\n",
    "  # 使用评估器对预测结果进行评估\n",
    "  evla_result = evaluator.evaluate_strings(\n",
    "    prediction=\"what is 2 + 2? that is an elementary question. The answer you are looking for is that two add two is four.\",\n",
    "    input=\"what is 2 + 2 ?\"\n",
    "  )\n",
    "\n",
    "  # 存储结果\n",
    "  results[model_name] = evla_result\n",
    "\n",
    "# 打印每个模型的评估结果\n",
    "for model, result in results.items():\n",
    "  print(f\"Model: {model}\")\n",
    "  print(f\"Evaluation Result: {result}\")\n",
    "  print(\"-\" * 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1f56d7cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.model_laboratory import ModelLaboratory\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain_ollama.llms import OllamaLLM\n",
    "# from langchain_community.llms.chatglm import ChatGLM\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "75ebf8ef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1mInput:\u001b[0m\n",
      "齐天大圣的师傅是谁？\n",
      "\n",
      "\u001b[1mOllamaLLM\u001b[0m\n",
      "Params: {}\n",
      "\u001b[36;1m\u001b[1;3m齐天大圣，即孙悟空，在《西游记》这部古典名著中，他的师傅是菩提老祖。在菩提老祖那里，孙悟空学会了七十二变、筋斗云等许多本领，并得到了金箍棒作为武器。后来，他成为了如来佛祖的弟子，取经路上的保护者之一。\u001b[0m\n",
      "\n",
      "\u001b[1mOllamaLLM\u001b[0m\n",
      "Params: {}\n",
      "\u001b[33;1m\u001b[1;3m<think>\n",
      "嗯，我现在要回答关于“齐天大圣”的问题。首先，我需要了解齐天大圣是谁。我记得齐天大圣是西游记中的一个角色，对吧？\n",
      "\n",
      "对了，齐天大圣其实有两个版本：一种是孙悟空的师傅，另一种可能是指另一个角色。让我仔细想想。\n",
      "\n",
      "首先，齐天大圣作为孙悟空的师傅，应该是唐僧的师父。因为唐僧和孙悟空都是西游记的主要人物，所以他们之间有师徒关系。那么，齐天大圣是谁呢？我记得他是唐僧的师父，对吧？\n",
      "\n",
      "然后，我需要确认一下，齐天大圣是不是还有其他角色。比如，可能在某些版本中，他有不同的名字或者身份。不过一般来说，齐天大圣作为孙悟空的师傅，应该是唐僧的师父。\n",
      "\n",
      "另外，齐天大圣的角色主要是帮助唐僧实现他的愿望，比如降下龙珠来拯救五斗米星人。所以，他是孙悟空的师傅，负责带领孙悟空完成任务。\n",
      "\n",
      "总结一下，齐天大圣是西游记中的一个角色，他实际上是孙悟空的师傅，也就是唐僧的师父。因此，答案应该是“齐天大圣是孙悟空的师傅，具体来说是他师从唐僧那里学习而来。”\n",
      "</think>\n",
      "\n",
      "齐天大圣是西游记中孙悟空的师傅，具体来说，他是唐僧的师父。他帮助孙悟空实现降下龙珠的目标，并带领孙悟空完成一系列重要的任务。因此，齐天大圣可以被理解为孙悟空的师傅角色。\u001b[0m\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 比较 本地 qwen2.5 7b   deepscaler\n",
    "llms = [\n",
    "  OllamaLLM(model=\"qwen2.5:7b\",temperature=0),\n",
    "  OllamaLLM(model=\"deepscaler:latest\",temperature=0),\n",
    "]\n",
    "\n",
    "model_lab = ModelLaboratory.from_llms(llms=llms)\n",
    "\n",
    "model_lab.compare(\"齐天大圣的师傅是谁？\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "4864d1b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.prompts import PromptTemplate\n",
    "from langchain.chains.llm import LLMChain\n",
    "\n",
    "prompt = PromptTemplate(\n",
    "  template=\"给我讲一个关于{topic}的笑话, 30个字左右\",\n",
    "  input_variables=[\"topic\"]\n",
    ")\n",
    "\n",
    "llm_qwen = OllamaLLM(model=\"qwen2.5:7b\",temperature=0)\n",
    "llm_deepsc = OllamaLLM(model=\"deepscaler:latest\",temperature=0)\n",
    "\n",
    "qwen_chain = LLMChain(\n",
    "  llm=llm_qwen,\n",
    "  prompt=prompt,\n",
    "  verbose=True\n",
    ")\n",
    "deepsc_chain = LLMChain(\n",
    "  llm=llm_deepsc,\n",
    "  prompt=prompt,\n",
    "  verbose=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "662f4ae1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['llm_qwen2.5', 'llm_deepscaler']"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chains = [qwen_chain, deepsc_chain]\n",
    "names = [\"llm_qwen2.5\", \"llm_deepscaler\"]\n",
    "names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "29a13d28",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1mInput:\u001b[0m\n",
      "炒股\n",
      "\n",
      "llm_qwen2.5\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new LLMChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3m给我讲一个关于炒股的笑话, 30个字左右\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "\u001b[36;1m\u001b[1;3m股票像美女，美丽让人欢喜让人忧。\u001b[0m\n",
      "\n",
      "llm_deepscaler\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new LLMChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3m给我讲一个关于炒股的笑话, 30个字左右\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "\u001b[33;1m\u001b[1;3m<think>\n",
      "嗯，用户让我讲一个关于炒股的笑话，要求30个字左右。首先，我需要理解用户的需求。他们可能是在寻找一种轻松有趣的方式来放松心情，或者作为娱乐内容使用。\n",
      "\n",
      "接下来，我要考虑如何将股票和笑话结合起来。通常，笑话会用一些幽默的语言或比喻来表达复杂的概念。比如，把炒股比作一场游戏，或者利用一些常见的金融术语来制造笑点。\n",
      "\n",
      "然后，我需要确保笑话简洁明了，符合字数要求。可能的结构是先引入一个情境，再提出一个问题，最后给出一个巧妙的答案。例如，提到“股市就像一场游戏”，然后用幽默的方式解释为什么有人会买股票。\n",
      "\n",
      "还要注意语言要口语化，避免过于正式或复杂的句子结构。这样可以让笑话更贴近大众生活，更容易被接受和理解。\n",
      "\n",
      "最后，检查字数是否在30个字左右，确保没有超过或不足。可能需要调整句子的长度，或者简化表达，以达到最佳效果。\n",
      "</think>\n",
      "\n",
      "股市就像一场游戏，你买不到赢，但总能让你赚到！\u001b[0m\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model_lab = ModelLaboratory(chains=chains, names=names)\n",
    "model_lab.compare(\"炒股\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "12f2b1b3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1mInput:\u001b[0m\n",
      "写作业\n",
      "\n",
      "llm_qwen2.5\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new LLMChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3m给我讲一个关于写作业的笑话, 30个字左右\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "\u001b[36;1m\u001b[1;3m老师没收了小明的作业，问：“你不是做了吗？”小明答：“做了，但作业本忘家里了。”\u001b[0m\n",
      "\n",
      "llm_deepscaler\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new LLMChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3m给我讲一个关于写作业的笑话, 30个字左右\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "\u001b[33;1m\u001b[1;3m<think>\n",
      "嗯，用户让我讲一个关于写作业的笑话，要求30个字左右。首先，我需要理解用户的需求。可能他们是在准备某种教学材料，或者想用幽默的方式帮助学生记住写作业的重要性。\n",
      "\n",
      "接下来，我要考虑笑话的结构和内容。通常笑话会有问题或谜题，然后给出答案，但这里要讲的是写作业的过程，所以可能需要用一个有趣的情节来引出主题。\n",
      "\n",
      "考虑到字数限制，30个字左右，我需要简洁明了地表达出来。或许可以从一个场景开始，比如在教室里，然后引入一个幽默的转折点。\n",
      "\n",
      "想到“写作业就像一场考试”，这样既点明了作业的重要性，又增加了趣味性。接着，可以加入一个搞笑的情节，比如老师出错，学生却没注意到，这样既有趣又符合主题。\n",
      "\n",
      "最后，总结一下，让整个笑话连贯且有笑点，同时传达出写作业的必要性和幽默感。\n",
      "</think>\n",
      "\n",
      "在教室里，小明正在认真地写着作业。这时，他发现老师出了一道数学题，结果把答案写错了。小明却没注意到，只是继续写着作业，最后交上来了。\n",
      "\n",
      "**答案：写作业就像一场考试，但只要认真对待，就不会像考试一样难过！**\u001b[0m\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model_lab.compare(\"写作业\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2692b56",
   "metadata": {},
   "source": [
    "## Set Debug && Set Verbose"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "f0544f5e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1mInput:\u001b[0m\n",
      "巧克力\n",
      "\n",
      "llm_qwen2.5\n",
      "\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[chain:LLMChain] Entering Chain run with input:\n",
      "\u001b[0m{\n",
      "  \"topic\": \"巧克力\"\n",
      "}\n",
      "\u001b[32;1m\u001b[1;3m[llm/start]\u001b[0m \u001b[1m[chain:LLMChain > llm:OllamaLLM] Entering LLM run with input:\n",
      "\u001b[0m{\n",
      "  \"prompts\": [\n",
      "    \"给我讲一个关于巧克力的笑话, 30个字左右\"\n",
      "  ]\n",
      "}\n",
      "\u001b[36;1m\u001b[1;3m[llm/end]\u001b[0m \u001b[1m[chain:LLMChain > llm:OllamaLLM] [3.18s] Exiting LLM run with output:\n",
      "\u001b[0m{\n",
      "  \"generations\": [\n",
      "    [\n",
      "      {\n",
      "        \"text\": \"巧克力掉进打印机，打印出一盒子巧克力来！\",\n",
      "        \"generation_info\": {\n",
      "          \"model\": \"qwen2.5:7b\",\n",
      "          \"created_at\": \"2025-04-07T08:22:42.354927Z\",\n",
      "          \"done\": true,\n",
      "          \"done_reason\": \"stop\",\n",
      "          \"total_duration\": 3158392625,\n",
      "          \"load_duration\": 29884167,\n",
      "          \"prompt_eval_count\": 43,\n",
      "          \"prompt_eval_duration\": 2479284417,\n",
      "          \"eval_count\": 13,\n",
      "          \"eval_duration\": 647394291,\n",
      "          \"response\": \"\",\n",
      "          \"context\": [\n",
      "            151644,\n",
      "            8948,\n",
      "            198,\n",
      "            2610,\n",
      "            525,\n",
      "            1207,\n",
      "            16948,\n",
      "            11,\n",
      "            3465,\n",
      "            553,\n",
      "            54364,\n",
      "            14817,\n",
      "            13,\n",
      "            1446,\n",
      "            525,\n",
      "            264,\n",
      "            10950,\n",
      "            17847,\n",
      "            13,\n",
      "            151645,\n",
      "            198,\n",
      "            151644,\n",
      "            872,\n",
      "            198,\n",
      "            104169,\n",
      "            99526,\n",
      "            46944,\n",
      "            101888,\n",
      "            110548,\n",
      "            9370,\n",
      "            109959,\n",
      "            11,\n",
      "            220,\n",
      "            18,\n",
      "            15,\n",
      "            18947,\n",
      "            18600,\n",
      "            101081,\n",
      "            151645,\n",
      "            198,\n",
      "            151644,\n",
      "            77091,\n",
      "            198,\n",
      "            110548,\n",
      "            100373,\n",
      "            41299,\n",
      "            117648,\n",
      "            3837,\n",
      "            102703,\n",
      "            20221,\n",
      "            14777,\n",
      "            110792,\n",
      "            110548,\n",
      "            36407,\n",
      "            6313\n",
      "          ]\n",
      "        },\n",
      "        \"type\": \"Generation\"\n",
      "      }\n",
      "    ]\n",
      "  ],\n",
      "  \"llm_output\": null,\n",
      "  \"run\": null,\n",
      "  \"type\": \"LLMResult\"\n",
      "}\n",
      "\u001b[36;1m\u001b[1;3m[chain/end]\u001b[0m \u001b[1m[chain:LLMChain] [3.18s] Exiting Chain run with output:\n",
      "\u001b[0m{\n",
      "  \"text\": \"巧克力掉进打印机，打印出一盒子巧克力来！\"\n",
      "}\n",
      "\u001b[36;1m\u001b[1;3m巧克力掉进打印机，打印出一盒子巧克力来！\u001b[0m\n",
      "\n",
      "llm_deepscaler\n",
      "\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[chain:LLMChain] Entering Chain run with input:\n",
      "\u001b[0m{\n",
      "  \"topic\": \"巧克力\"\n",
      "}\n",
      "\u001b[32;1m\u001b[1;3m[llm/start]\u001b[0m \u001b[1m[chain:LLMChain > llm:OllamaLLM] Entering LLM run with input:\n",
      "\u001b[0m{\n",
      "  \"prompts\": [\n",
      "    \"给我讲一个关于巧克力的笑话, 30个字左右\"\n",
      "  ]\n",
      "}\n",
      "\u001b[36;1m\u001b[1;3m[llm/end]\u001b[0m \u001b[1m[chain:LLMChain > llm:OllamaLLM] [14.08s] Exiting LLM run with output:\n",
      "\u001b[0m{\n",
      "  \"generations\": [\n",
      "    [\n",
      "      {\n",
      "        \"text\": \"<think>\\n嗯，用户让我讲一个关于巧克力的笑话，要求30个字左右。首先，我需要考虑用户可能的背景。可能是学生、老师，或者是喜欢幽默的人。他们可能想通过这个笑话来放松心情，或者作为课堂上的例子。\\n\\n接下来，我要确定笑话的主题。巧克力是一个很好的主题，因为它常见且容易引起共鸣。考虑到字数限制，笑话要简洁明了，同时要有一定的趣味性。\\n\\n然后，我需要构思一个场景。比如，一个孩子在吃巧克力，突然想到什么，这样可以制造笑点。或者，利用巧克力的特性，比如外皮剥开后变成糖果，这样既有趣又容易描述。\\n\\n再考虑结构。通常笑话有开头、发展和结尾。开头可以是孩子吃巧克力的情景，发展部分可能涉及到隐藏的秘密或幽默的事情，结尾则是一个温馨或有趣的结局。\\n\\n最后，确保字数在30个左右，不要太长或太短。同时，语言要生动有趣，能够引起读者的共鸣。\\n\\n综合以上思考，我想到一个笑话：一个孩子在吃巧克力时突然发现外皮剥开后变成糖果，于是问妈妈为什么，妈妈回答说因为外皮是巧克力，剥开后才是糖果。这样既简单又有趣，符合用户的要求。\\n</think>\\n\\n一个孩子在吃巧克力时突然发现外皮剥开后变成糖果，于是问妈妈为什么，妈妈回答说因为外皮是巧克力，剥开后才是糖果。\",\n",
      "        \"generation_info\": {\n",
      "          \"model\": \"deepscaler:latest\",\n",
      "          \"created_at\": \"2025-04-07T08:22:56.438514Z\",\n",
      "          \"done\": true,\n",
      "          \"done_reason\": \"stop\",\n",
      "          \"total_duration\": 14074318917,\n",
      "          \"load_duration\": 13203292,\n",
      "          \"prompt_eval_count\": 17,\n",
      "          \"prompt_eval_duration\": 1082072542,\n",
      "          \"eval_count\": 305,\n",
      "          \"eval_duration\": 12978534958,\n",
      "          \"response\": \"\",\n",
      "          \"context\": [\n",
      "            151644,\n",
      "            104169,\n",
      "            99526,\n",
      "            46944,\n",
      "            101888,\n",
      "            110548,\n",
      "            9370,\n",
      "            109959,\n",
      "            11,\n",
      "            220,\n",
      "            18,\n",
      "            15,\n",
      "            18947,\n",
      "            18600,\n",
      "            101081,\n",
      "            151645,\n",
      "            151648,\n",
      "            198,\n",
      "            106287,\n",
      "            3837,\n",
      "            20002,\n",
      "            104029,\n",
      "            99526,\n",
      "            46944,\n",
      "            101888,\n",
      "            110548,\n",
      "            9370,\n",
      "            109959,\n",
      "            3837,\n",
      "            101882,\n",
      "            18,\n",
      "            15,\n",
      "            18947,\n",
      "            18600,\n",
      "            101081,\n",
      "            1773,\n",
      "            101140,\n",
      "            3837,\n",
      "            35946,\n",
      "            85106,\n",
      "            101118,\n",
      "            20002,\n",
      "            87267,\n",
      "            9370,\n",
      "            102193,\n",
      "            1773,\n",
      "            104560,\n",
      "            99720,\n",
      "            5373,\n",
      "            101049,\n",
      "            3837,\n",
      "            105471,\n",
      "            99729,\n",
      "            108460,\n",
      "            100623,\n",
      "            1773,\n",
      "            99650,\n",
      "            87267,\n",
      "            99172,\n",
      "            67338,\n",
      "            99487,\n",
      "            109959,\n",
      "            36407,\n",
      "            105270,\n",
      "            104753,\n",
      "            3837,\n",
      "            100631,\n",
      "            100622,\n",
      "            102428,\n",
      "            101913,\n",
      "            103358,\n",
      "            3407,\n",
      "            104326,\n",
      "            3837,\n",
      "            104515,\n",
      "            60610,\n",
      "            109959,\n",
      "            109151,\n",
      "            1773,\n",
      "            110548,\n",
      "            101909,\n",
      "            104528,\n",
      "            100220,\n",
      "            3837,\n",
      "            108884,\n",
      "            101536,\n",
      "            100136,\n",
      "            100047,\n",
      "            100771,\n",
      "            113178,\n",
      "            1773,\n",
      "            106350,\n",
      "            18600,\n",
      "            8863,\n",
      "            104108,\n",
      "            3837,\n",
      "            109959,\n",
      "            30534,\n",
      "            110485,\n",
      "            30858,\n",
      "            34187,\n",
      "            3837,\n",
      "            91572,\n",
      "            105916,\n",
      "            102495,\n",
      "            108154,\n",
      "            33071,\n",
      "            3407,\n",
      "            101889,\n",
      "            3837,\n",
      "            35946,\n",
      "            85106,\n",
      "            118444,\n",
      "            46944,\n",
      "            102122,\n",
      "            1773,\n",
      "            101912,\n",
      "            3837,\n",
      "            46944,\n",
      "            99657,\n",
      "            18493,\n",
      "            99405,\n",
      "            110548,\n",
      "            3837,\n",
      "            103961,\n",
      "            101303,\n",
      "            99245,\n",
      "            3837,\n",
      "            99654,\n",
      "            73670,\n",
      "            100184,\n",
      "            48738,\n",
      "            27442,\n",
      "            1773,\n",
      "            100631,\n",
      "            3837,\n",
      "            100152,\n",
      "            110548,\n",
      "            9370,\n",
      "            105539,\n",
      "            3837,\n",
      "            101912,\n",
      "            47815,\n",
      "            99888,\n",
      "            101819,\n",
      "            29767,\n",
      "            33447,\n",
      "            104286,\n",
      "            114739,\n",
      "            3837,\n",
      "            99654,\n",
      "            99929,\n",
      "            103027,\n",
      "            99518,\n",
      "            100047,\n",
      "            53481,\n",
      "            3407,\n",
      "            87256,\n",
      "            101118,\n",
      "            100166,\n",
      "            1773,\n",
      "            102119,\n",
      "            109959,\n",
      "            18830,\n",
      "            111749,\n",
      "            5373,\n",
      "            99185,\n",
      "            33108,\n",
      "            114903,\n",
      "            1773,\n",
      "            111749,\n",
      "            73670,\n",
      "            20412,\n",
      "            99657,\n",
      "            99405,\n",
      "            110548,\n",
      "            101747,\n",
      "            85254,\n",
      "            3837,\n",
      "            99185,\n",
      "            99659,\n",
      "            87267,\n",
      "            109228,\n",
      "            71694,\n",
      "            111719,\n",
      "            57191,\n",
      "            108460,\n",
      "            103976,\n",
      "            3837,\n",
      "            114903,\n",
      "            46448,\n",
      "            101909,\n",
      "            103002,\n",
      "            57191,\n",
      "            107935,\n",
      "            107062,\n",
      "            3407,\n",
      "            100161,\n",
      "            3837,\n",
      "            103944,\n",
      "            18600,\n",
      "            8863,\n",
      "            18493,\n",
      "            18,\n",
      "            15,\n",
      "            18947,\n",
      "            101081,\n",
      "            3837,\n",
      "            115596,\n",
      "            45861,\n",
      "            57191,\n",
      "            99222,\n",
      "            99534,\n",
      "            1773,\n",
      "            91572,\n",
      "            3837,\n",
      "            102064,\n",
      "            30534,\n",
      "            106267,\n",
      "            103027,\n",
      "            3837,\n",
      "            100006,\n",
      "            100771,\n",
      "            104785,\n",
      "            9370,\n",
      "            113178,\n",
      "            3407,\n",
      "            99799,\n",
      "            70589,\n",
      "            104107,\n",
      "            3837,\n",
      "            35946,\n",
      "            101303,\n",
      "            46944,\n",
      "            109959,\n",
      "            5122,\n",
      "            46944,\n",
      "            99657,\n",
      "            18493,\n",
      "            99405,\n",
      "            110548,\n",
      "            13343,\n",
      "            103961,\n",
      "            99879,\n",
      "            47815,\n",
      "            99888,\n",
      "            101819,\n",
      "            29767,\n",
      "            33447,\n",
      "            104286,\n",
      "            114739,\n",
      "            3837,\n",
      "            101959,\n",
      "            56007,\n",
      "            101935,\n",
      "            100678,\n",
      "            3837,\n",
      "            101935,\n",
      "            102104,\n",
      "            36587,\n",
      "            99519,\n",
      "            47815,\n",
      "            99888,\n",
      "            20412,\n",
      "            110548,\n",
      "            3837,\n",
      "            101819,\n",
      "            29767,\n",
      "            33447,\n",
      "            101258,\n",
      "            114739,\n",
      "            1773,\n",
      "            99654,\n",
      "            99929,\n",
      "            100405,\n",
      "            99518,\n",
      "            103027,\n",
      "            3837,\n",
      "            101137,\n",
      "            20002,\n",
      "            104272,\n",
      "            8997,\n",
      "            151649,\n",
      "            271,\n",
      "            46944,\n",
      "            99657,\n",
      "            18493,\n",
      "            99405,\n",
      "            110548,\n",
      "            13343,\n",
      "            103961,\n",
      "            99879,\n",
      "            47815,\n",
      "            99888,\n",
      "            101819,\n",
      "            29767,\n",
      "            33447,\n",
      "            104286,\n",
      "            114739,\n",
      "            3837,\n",
      "            101959,\n",
      "            56007,\n",
      "            101935,\n",
      "            100678,\n",
      "            3837,\n",
      "            101935,\n",
      "            102104,\n",
      "            36587,\n",
      "            99519,\n",
      "            47815,\n",
      "            99888,\n",
      "            20412,\n",
      "            110548,\n",
      "            3837,\n",
      "            101819,\n",
      "            29767,\n",
      "            33447,\n",
      "            101258,\n",
      "            114739,\n",
      "            1773\n",
      "          ]\n",
      "        },\n",
      "        \"type\": \"Generation\"\n",
      "      }\n",
      "    ]\n",
      "  ],\n",
      "  \"llm_output\": null,\n",
      "  \"run\": null,\n",
      "  \"type\": \"LLMResult\"\n",
      "}\n",
      "\u001b[36;1m\u001b[1;3m[chain/end]\u001b[0m \u001b[1m[chain:LLMChain] [14.08s] Exiting Chain run with output:\n",
      "\u001b[0m{\n",
      "  \"text\": \"<think>\\n嗯，用户让我讲一个关于巧克力的笑话，要求30个字左右。首先，我需要考虑用户可能的背景。可能是学生、老师，或者是喜欢幽默的人。他们可能想通过这个笑话来放松心情，或者作为课堂上的例子。\\n\\n接下来，我要确定笑话的主题。巧克力是一个很好的主题，因为它常见且容易引起共鸣。考虑到字数限制，笑话要简洁明了，同时要有一定的趣味性。\\n\\n然后，我需要构思一个场景。比如，一个孩子在吃巧克力，突然想到什么，这样可以制造笑点。或者，利用巧克力的特性，比如外皮剥开后变成糖果，这样既有趣又容易描述。\\n\\n再考虑结构。通常笑话有开头、发展和结尾。开头可以是孩子吃巧克力的情景，发展部分可能涉及到隐藏的秘密或幽默的事情，结尾则是一个温馨或有趣的结局。\\n\\n最后，确保字数在30个左右，不要太长或太短。同时，语言要生动有趣，能够引起读者的共鸣。\\n\\n综合以上思考，我想到一个笑话：一个孩子在吃巧克力时突然发现外皮剥开后变成糖果，于是问妈妈为什么，妈妈回答说因为外皮是巧克力，剥开后才是糖果。这样既简单又有趣，符合用户的要求。\\n</think>\\n\\n一个孩子在吃巧克力时突然发现外皮剥开后变成糖果，于是问妈妈为什么，妈妈回答说因为外皮是巧克力，剥开后才是糖果。\"\n",
      "}\n",
      "\u001b[33;1m\u001b[1;3m<think>\n",
      "嗯，用户让我讲一个关于巧克力的笑话，要求30个字左右。首先，我需要考虑用户可能的背景。可能是学生、老师，或者是喜欢幽默的人。他们可能想通过这个笑话来放松心情，或者作为课堂上的例子。\n",
      "\n",
      "接下来，我要确定笑话的主题。巧克力是一个很好的主题，因为它常见且容易引起共鸣。考虑到字数限制，笑话要简洁明了，同时要有一定的趣味性。\n",
      "\n",
      "然后，我需要构思一个场景。比如，一个孩子在吃巧克力，突然想到什么，这样可以制造笑点。或者，利用巧克力的特性，比如外皮剥开后变成糖果，这样既有趣又容易描述。\n",
      "\n",
      "再考虑结构。通常笑话有开头、发展和结尾。开头可以是孩子吃巧克力的情景，发展部分可能涉及到隐藏的秘密或幽默的事情，结尾则是一个温馨或有趣的结局。\n",
      "\n",
      "最后，确保字数在30个左右，不要太长或太短。同时，语言要生动有趣，能够引起读者的共鸣。\n",
      "\n",
      "综合以上思考，我想到一个笑话：一个孩子在吃巧克力时突然发现外皮剥开后变成糖果，于是问妈妈为什么，妈妈回答说因为外皮是巧克力，剥开后才是糖果。这样既简单又有趣，符合用户的要求。\n",
      "</think>\n",
      "\n",
      "一个孩子在吃巧克力时突然发现外皮剥开后变成糖果，于是问妈妈为什么，妈妈回答说因为外皮是巧克力，剥开后才是糖果。\u001b[0m\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from langchain.globals import set_debug\n",
    "set_debug(True)\n",
    "model_lab.compare(\"巧克力\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "d1a3d656",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1mInput:\u001b[0m\n",
      "巧克力\n",
      "\n",
      "llm_qwen2.5\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new LLMChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3m给我讲一个关于巧克力的笑话, 30个字左右\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "\u001b[36;1m\u001b[1;3m巧克力掉进打印机，打印出一盒子巧克力来！\u001b[0m\n",
      "\n",
      "llm_deepscaler\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new LLMChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3m给我讲一个关于巧克力的笑话, 30个字左右\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "\u001b[33;1m\u001b[1;3m<think>\n",
      "嗯，用户让我讲一个关于巧克力的笑话，要求30个字左右。首先，我需要考虑用户可能的背景。可能是学生、老师，或者是喜欢幽默的人。他们可能想通过这个笑话来放松心情，或者作为课堂上的例子。\n",
      "\n",
      "接下来，我要确定笑话的主题。巧克力是一个很好的主题，因为它常见且容易引起共鸣。考虑到字数限制，笑话要简洁明了，同时要有一定的趣味性。\n",
      "\n",
      "然后，我需要构思一个场景。比如，一个孩子在吃巧克力，突然想到什么，这样可以制造笑点。或者，利用巧克力的特性，比如外皮剥开后变成糖果，这样既有趣又容易描述。\n",
      "\n",
      "再考虑结构。通常笑话有开头、发展和结尾。开头可以是孩子吃巧克力的情景，发展部分可能涉及到隐藏的秘密或幽默的事情，结尾则是一个温馨或有趣的结局。\n",
      "\n",
      "最后，确保字数在30个左右，不要太长或太短。同时，语言要生动有趣，能够引起读者的共鸣。\n",
      "\n",
      "综合以上思考，我想到一个笑话：一个孩子在吃巧克力时突然发现外皮剥开后变成糖果，于是问妈妈为什么，妈妈回答说因为外皮是巧克力，剥开后才是糖果。这样既简单又有趣，符合用户的要求。\n",
      "</think>\n",
      "\n",
      "一个孩子在吃巧克力时突然发现外皮剥开后变成糖果，于是问妈妈为什么，妈妈回答说因为外皮是巧克力，剥开后才是糖果。\u001b[0m\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from langchain.globals import set_verbose\n",
    "set_verbose(True)\n",
    "set_debug(False)\n",
    "model_lab.compare(\"巧克力\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "rag",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
